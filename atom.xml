<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>pEacill</title>
  
  
  <link href="https://peacill.online/atom.xml" rel="self"/>
  
  <link href="https://peacill.online/"/>
  <updated>2025-01-03T09:04:09.617Z</updated>
  <id>https://peacill.online/</id>
  
  <author>
    <name>pEacill</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>C++ concurrent data structures based on lock</title>
    <link href="https://peacill.online/post/20527.html"/>
    <id>https://peacill.online/post/20527.html</id>
    <published>2025-01-02T10:24:26.000Z</published>
    <updated>2025-01-03T09:04:09.617Z</updated>
    
    <content type="html"><![CDATA[<p>本文将介绍一些c++中基于锁实现的并发数据结构。包括线程安全的Stack、Queue、List和Map。本文代码主要基于c++14，有时也会使用一些c++17和c++20的新特性，同时会使用到一些基本的特性和并发开发工具，文中不会详细介绍，建议查阅资料或书籍《c++并发编程实战》。文中也会体现一些并发编程的基本思想和思考。</p><p>完整代码在GitHub：<a href="https://github.com/pEacill/Thread-safe-data-structure">GitHub</a></p><h1 id="如何实现并发"><a href="#如何实现并发" class="headerlink" title="如何实现并发"></a>如何实现并发</h1><p>主要需要考虑两个方面，一个方面是确保访问的安全，另一方面是实现真正的并发。</p><p>如何确保数据的线程安全：</p><ul><li>确保没有线程可以看到不变量的中间状态（修改过程对其它线程不可见）。</li><li>小心会引起条件竞争的接口，可以选择提供完整的操作函数，而不是单一步骤。</li><li>防止异常的发生而导致数据丢失。</li><li>防止死锁的产生。</li></ul><blockquote><p><strong>如何防止死锁：</strong></p><ol><li>避免嵌套锁：尽量不要在持有一个锁的情况下再去请求另一个锁。</li><li>避免在持有锁时调用外部代码：外部程序可能做任何事情，包括获取锁。在持有锁的情况下，如果用外部代码要获取一个锁，就会违反1，并造成死锁。</li><li>使用固定顺序获取锁：当硬性要求获取两个或两个以上的锁，并且不能使用 std::lock 单独操作来获取它们时，最好在每个线程上，用固定的顺序获取锁。（如链表中的手递手草组）</li><li>使用层次锁结构：对互斥量进行分层，按照优先级来获取锁。如持有一个锁后只能获取更低层次的锁，而不允许获得高层次的锁，除非释放当前锁。</li></ol></blockquote><p>如何实现高效的并发，考虑以下问题：</p><ul><li>操作在锁的范围中进行，是否允许在锁外执行？</li><li>数据结构中不同的互斥量能否保护不同的区域？</li><li>所有操作都需要同级互斥量的保护吗？</li><li>能否对数据结构进行简单的修改，增加并发访问的概率？</li></ul><h1 id="Stack"><a href="#Stack" class="headerlink" title="Stack"></a>Stack</h1><p>我们从一个最简单的栈开始，接口如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">threadsafe_stack</span>&#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::stack&lt;T&gt; data;</span><br><span class="line">    <span class="keyword">mutable</span> std::mutex m;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">threadsafe_stack</span>(): <span class="built_in">data</span>(std::<span class="built_in">stack</span>&lt;T&gt;()) &#123;&#125;</span><br><span class="line">    <span class="built_in">threadsafe_stack</span>(<span class="type">const</span> threadsafe_stack&amp; other)&#123;</span><br><span class="line">        <span class="function">std::lock_guard <span class="title">lock</span><span class="params">(other.m)</span></span>;</span><br><span class="line">        data = other.data;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    threadsafe_stack&amp; <span class="keyword">operator</span>=(<span class="type">const</span> threadsafe_stack&amp;) = <span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">push</span><span class="params">(T new_value)</span></span>;</span><br><span class="line">    <span class="function">std::shared_ptr&lt;T&gt; <span class="title">pop</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">pop</span><span class="params">(T&amp; value)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">empty</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实现中使用一个互斥量（mutex）m来对每个成员函数进行加锁保护。保证在同一时间内，只有一个线程可以访问到数据。同时会使用一些RAII模版类来进行互斥量资源的管理，如std::lock_guard。在并发访问的数据结构中，最主要的设计要素就是保证整个数据结构的异常安全，同时注意接口之间的条件竞争。</p><blockquote><p><strong>为什么没有top()?</strong><br>在多线程环境中，保持数据一致性是至关重要的。top()可以让用户在不修改栈的情况下查看栈顶元素，这会导致一些特殊的情况，如：如果在调用 top() 之后立即调用 pop()，而另一个线程也在操作同一个栈，这可能导致不一致的状态。同时，注意如果我们在top()中返回了对一个共享数据的应用，那整个数据结构的并发安全就会被打破，因为持有这个引用的一方可以在不获得互斥量的情况下访问共享数据。<br>尽管没有实现 top() 方法，但可以通过其他方式来获取栈顶元素。例如，可以使用第二个重载的 pop(T&amp; value) 方法来获取栈顶元素并将其存储在提供的引用变量中。这样，用户仍然可以获取栈顶元素而不必直接移除它。</p><p><strong>接口间竞争</strong><br>如我们在调用empty()后调用top()，那么有可能其它的线程已经修改了数据结构，这里的top()会得到错误的结果，也就是我们常说的存在数据竞争。</p><p><strong>为什么有两个重载的pop()</strong><br>这里主要要解决的问题是，试想这样一个数据结构std::stack&lt;vector<int>&gt;，vector是个动态容器，当拷贝一个动态容器时，标准库会从堆上分配很多内存来完成这次拷贝。当这个系统处在重度负荷，或有严重的资源限制的情况下，这种内存分配就会失败，所以vector的拷贝构造函数可能会抛出一个 std::bad_alloc 异常。当vector中存有大量元素时，这种情况发生的可能性更大。当pop()函数返回“弹出值”时(也就是从栈中将这个值移除)，会有一个潜在的问题：这个值返回到调用函数的时候，栈才被改变。但拷贝数据的时候，调用函数抛出一个异常会怎么样？ 如果真的发生了，要弹出的数据将会丢失，它的确从栈上移除了，但是拷贝失败了。为了解决这个问题，共有以下几种方法：</p><ol><li>传入一个引用（void pop(T&amp; value);），用来接收“弹出值”。它的缺点是：需要构造出一个栈中类型的实例，用于接收目标值。对于一些类型，这样做是不现实的，因为临时构造一个实例，从时间和资源的角度上来看都不划算。</li><li>返回指向弹出值的指针。指针的优势是自由拷贝，并且不会产生异常。为了避免内存泄漏，鼓励使用使用 std::shared_ptr。<br>所以，为了通用性，我们应当提供以上两种接口，由用户选择具体使用那种。</li></ol><p><strong>为什么使用mutable</strong><br>为了支持在const成员函数中安全地修改该互斥量，如empty();</p></blockquote><p>首先来看两个pop接口的实现：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::shared_ptr&lt;T&gt; <span class="title">pop</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(m)</span></span>;</span><br><span class="line">    <span class="keyword">if</span>(data.<span class="built_in">empty</span>()) <span class="keyword">throw</span> <span class="built_in">empty_stack</span>();</span><br><span class="line"></span><br><span class="line">    <span class="function">std::shared_ptr&lt;T&gt; <span class="type">const</span> <span class="title">res</span><span class="params">(std::make_shared&lt;T&gt;(data.top()))</span></span>;</span><br><span class="line"></span><br><span class="line">    data.<span class="built_in">pop</span>();</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">pop</span><span class="params">(T&amp; value)</span></span>&#123;</span><br><span class="line">    <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(m)</span></span>;</span><br><span class="line">    <span class="keyword">if</span>(data.<span class="built_in">empty</span>()) <span class="keyword">throw</span> <span class="built_in">empty_stack</span>();</span><br><span class="line"></span><br><span class="line">    value = data.<span class="built_in">top</span>();</span><br><span class="line">    data.<span class="built_in">pop</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>pop()第一个重载中，代码可能会抛出empty_stack异常,但是，并没有数据的修改，所以这里是异常安全的。创建res时，也可能会抛出异常（std::make_shared 无法分配出足够的内存去创建新对象，拷贝或移动构造到新分配的内存中时抛出异常），两种情况都有c++标准库和运行时库来保证不会出现内存泄漏，并且新创建的对象(如果有的话)都能正确销毁。因为没有对栈进行任何修改，所以这里也没问题。</p><p>第二个重载pop()除了在拷贝赋值或移动赋值时会抛出异常，同样，在调用data.pop()之前，没有对数据结构进行修改，所以这个函数也是异常安全的。</p><p>empty()不会对数据进行修改，所以也是异常安全的。</p><p>注意，这里的构造和析构函数并不是线程安全的。所以，用户就要保证在栈对象完成构建前，其他线程无法对其进行访问。并且，要保证在栈对象销毁后，停止所有线程的访问操作。</p><h1 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h1><p>首先是一个大家比较能够接受的版本：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">threadsafe_queue</span>&#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">mutable</span> std::mutex mut;</span><br><span class="line">    std::condition_variable data_cond;</span><br><span class="line">    std::queue&lt;T&gt; data_queue;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">threadsafe_queue</span>() &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">push</span><span class="params">(T data)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">wait_and_pop</span><span class="params">(T&amp; value)</span>l</span>;</span><br><span class="line">    <span class="function">std::shared_ptr&lt;T&gt; <span class="title">wait_and_pop</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">try_pop</span><span class="params">(T&amp; value)</span></span>;</span><br><span class="line">    <span class="function">std::shared_ptr&lt;T&gt; <span class="title">try_pop</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">empty</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个版本使用tls库中的queue作为底层的数据结构，同时使用互斥量和调教变量来提供线程间的互斥与同步。我们来看看push()和wait_and_pop()接口：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">push</span><span class="params">(T data)</span></span>&#123;</span><br><span class="line">    <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mut)</span></span>;</span><br><span class="line">    data_queue.<span class="built_in">push</span>(std::<span class="built_in">move</span>(data));</span><br><span class="line">    data_cond.<span class="built_in">notify_one</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">wait_and_pop</span><span class="params">(T&amp; value)</span></span>&#123;</span><br><span class="line">    <span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mut)</span></span>;</span><br><span class="line">    data_cond.<span class="built_in">wait</span>(lock, [<span class="keyword">this</span>](<span class="keyword">return</span> !data_queue.<span class="built_in">empty</span>();));</span><br><span class="line">    value = std::<span class="built_in">move</span>(data_queue.<span class="built_in">front</span>());</span><br><span class="line">    data_queue.<span class="built_in">pop</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">std::shared_ptr&lt;T&gt; <span class="title">wait_and_pop</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(mut)</span></span>;</span><br><span class="line">    data_cond.<span class="built_in">wait</span>(lock, [<span class="keyword">this</span>]&#123;<span class="keyword">return</span> !data_queue.<span class="built_in">empty</span>();&#125;);</span><br><span class="line">    <span class="function">std::shared_ptr&lt;T&gt; <span class="title">res</span><span class="params">(std::make_shared&lt;T&gt;(std::move(data_queue.front())))</span></span>;</span><br><span class="line">    data_queue.<span class="built_in">pop</span>();</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p><strong>为什么使用std::move()</strong><br>将左指转换为右值，从而避免不必要的拷贝。</p><p><strong>为什么使用条件变量</strong></p><ol><li>避免忙等待。忙等待会浪费 CPU 资源，因为线程会在无效的检查中消耗计算资源。使用条件变量后，线程可以安全地进入休眠状态，直到被唤醒。</li><li>释放互斥锁。条件变量会自动释放与之关联的互斥锁（mutex），允许其他线程获得锁并修改共享数据。当条件满足后，等待的线程会被唤醒，并尝试重新获取锁。这种机制确保了在等待期间不会有其他线程阻塞。</li></ol><p><strong>为什么有try_pop</strong><br>在队列中存在数据时返回pop的数据，不存在数据时返回空。</p></blockquote><p>代码中存在一些潜在的问题，如data_cond.notify_one()会导致一个潜在的异常情况，比如一个线程在wait_and_pop中抛出异常，那么其它的线程将永远无法被唤醒，因为当前只会有这一个工作线程。</p><p>可以采用以下修改，比如我们的queue中存储的数据不再是原始数据，而是一个指向原始数据的指针，这样就能使wait_and_pop()安全的工作。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">threadsafe_queue</span>&#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">mutable</span> std::mutex mut;</span><br><span class="line">    std::queue&lt;std::shared_ptr&lt;T&gt; &gt; data_queue;</span><br><span class="line">    std::condition_variable data_cond;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">push</span><span class="params">(T new_value)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="function">std::shared_ptr&lt;T&gt; <span class="title">data</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">            std::make_shared&lt;T&gt;(std::move(new_value)))</span></span>;</span><br><span class="line">        <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lk</span><span class="params">(mut)</span></span>;</span><br><span class="line">        data_queue.<span class="built_in">push</span>(data);</span><br><span class="line">        data_cond.<span class="built_in">notify_one</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">std::shared_ptr&lt;T&gt; <span class="title">wait_and_pop</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">lk</span><span class="params">(mut)</span></span>;</span><br><span class="line">        data_cond.<span class="built_in">wait</span>(lk,[<span class="keyword">this</span>]&#123;<span class="keyword">return</span> !data_queue.<span class="built_in">empty</span>();&#125;);</span><br><span class="line">        std::shared_ptr&lt;T&gt; res=data_queue.<span class="built_in">front</span>();</span><br><span class="line">        data_queue.<span class="built_in">pop</span>();</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意这里push()中加锁的位置，对data的构造是无需加锁的，提前加锁只会导致更长的等待时间。</p><p>至此，使用tls库中queue的实现就差不多结束了，但是思考这样一个问题，队列是一头只执行push操作，而另一头只执行pop操作，我们对整个队列加锁会使后续的pop和push操作均处于等待，所以我们可以考虑不使用tls库中的queue，该用其它的数据结构实现队列，同时提供更细粒度的锁来实现性能更佳的并发。</p><p>使用更细粒度的锁来实现队列可以考虑将底层的数据结构更换为单链表，因为使用单链表我们可以对单个节点加锁。所以我们可以通过减少上锁的时间来实现更大程度的并发。</p><p>接口如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">threadsafe_queue</span>&#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">node</span> &#123;</span><br><span class="line">        std::shared_ptr&lt;T&gt; data;</span><br><span class="line">        std::unique_ptr&lt;node&gt; next;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    std::mutex head_mutex,tail_mutex;</span><br><span class="line">    std::condition_variable data_cond;</span><br><span class="line">    std::unique_ptr head;</span><br><span class="line">    node* tail;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">threadsafe_queue</span>():</span><br><span class="line">        <span class="built_in">head</span>(<span class="keyword">new</span> node), <span class="built_in">tail</span>(head.<span class="built_in">get</span>())</span><br><span class="line">    &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">threadsafe_queue</span>(<span class="type">const</span> threadsafe_queue&amp; other) = <span class="keyword">delete</span>;</span><br><span class="line">    threadsafe_queue&amp; <span class="keyword">operator</span>=(<span class="type">const</span> threadsafe_queue&amp; other) = <span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">std::shared_ptr&lt;T&gt; <span class="title">try_pop</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">try_pop</span><span class="params">(T&amp; value)</span></span>;</span><br><span class="line">    <span class="function">std::shared_ptr&lt;T&gt; <span class="title">wati_and_pop</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">wait_and_pop</span><span class="params">(T&amp; value)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">push</span><span class="params">(T new_value)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">empty</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p> <strong>为什么构造函数中预分配节点</strong><br>因为如果没有预分配的节点，那么在push和pop操作时需要持有两个互斥量，预分配节点后可以消除这种数据竞争。</p><p><strong>为什么删除拷贝构造函数和拷贝复制运算符</strong></p></blockquote><p>实现时需要注意有些函数是需要同时访问头尾指针的，如try_pop()，他需要首先判断队列是否为空，这需要同时对头尾指针进行操作。这个时候我们可以使用一些辅助函数来得到尾指针所在的值。如：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">node* <span class="title">get_tail</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">tail_lock</span><span class="params">(tail_mutex)</span></span>;</span><br><span class="line">    <span class="keyword">return</span> tail;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是如果你使用了get_tail来判断队列是否为空时，就需要确保一些操作的加锁顺序，如pop操作，如果你在获取队头锁之前调用了get_tail，之后在获取队头锁那么有可能会有潜在的数据竞争，因为在这两个操作之间可能已经有其它的线程pop了队列，并使队列为空，那么你的操作就会存在未定义的风险。</p><p>接下来是一些接口实现：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="type">void</span> threadsafe_queue&lt;T&gt;::<span class="built_in">push</span>(T new_value)&#123;</span><br><span class="line">    <span class="function">std::shared_ptr&lt;T&gt; <span class="title">new_data</span><span class="params">(std::make_shared(std::move(new_value)))</span></span>;</span><br><span class="line">    <span class="function">std::unique_ptr&lt;node&gt; <span class="title">p</span><span class="params">(<span class="keyword">new</span> node)</span></span>;</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">tail_lock</span><span class="params">(tail_mutex)</span></span>;</span><br><span class="line">        tail-&gt;data = new_data;</span><br><span class="line">        node* <span class="type">const</span> new_tail = p.<span class="built_in">get</span>();</span><br><span class="line">        tail-&gt;next = std::<span class="built_in">move</span>(p);</span><br><span class="line">        tail = new_tail;</span><br><span class="line">    &#125; </span><br><span class="line">    data_cond.<span class="built_in">notify_one</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意加锁的位置和具体实现，这里提前构造好新的尾部虚拟节点，并在缓冲区内只存在指针的操作，而不存在具体的数据构造，这样可以减少锁持有的时间。</p><p>try_pop和wait_and_pop的接口如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">std::shared_ptr&lt;T&gt; threadsafe_queue&lt;T&gt;::<span class="built_in">try_pop</span>()&#123;</span><br><span class="line">    std::unique_ptr&lt;<span class="keyword">typename</span> threadsafe_queue&lt;T&gt;::node&gt; <span class="type">const</span> old_head = threadsafe_queue&lt;T&gt;::<span class="built_in">try_pop_head</span>();</span><br><span class="line">    <span class="keyword">return</span> old_head ? old_head -&gt; data : std::<span class="built_in">shared_ptr</span>&lt;T&gt;();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="type">bool</span> threadsafe_queue&lt;T&gt;::<span class="built_in">try_pop</span>(T&amp; value)&#123;</span><br><span class="line">    std::unique_ptr&lt;<span class="keyword">typename</span> threadsafe_queue&lt;T&gt;::node&gt; <span class="type">const</span> old_head = threadsafe_queue&lt;T&gt;::<span class="built_in">try_pop_head</span>(value);</span><br><span class="line">    <span class="keyword">return</span> old_head;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">std::shared_ptr&lt;T&gt; threadsafe_queue&lt;T&gt;::<span class="built_in">wait_and_pop</span>()&#123;</span><br><span class="line">    std::unique_ptr&lt;node&gt; <span class="type">const</span> old_head = <span class="built_in">wait_pop_head</span>();</span><br><span class="line">    <span class="keyword">return</span> old_head -&gt; data;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="type">void</span> threadsafe_queue&lt;T&gt;::<span class="built_in">wait_and_pop</span>(T&amp; value)&#123;</span><br><span class="line">    std::unique_ptr&lt;node&gt; <span class="type">const</span> old_head = <span class="built_in">wait_pop_head</span>(value);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">wait_for_data</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">head_lock</span><span class="params">(head_mutex)</span></span>;</span><br><span class="line">    data_cond.<span class="built_in">wait</span>(head_lock, [&amp;]&#123;<span class="keyword">return</span> head.<span class="built_in">get</span>() != <span class="built_in">get_tail</span>();&#125;);</span><br><span class="line">    <span class="keyword">return</span> std::<span class="built_in">move</span>(head_lock);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">std::unique_ptr&lt;node&gt; <span class="title">wait_pop_head</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">head_lock</span><span class="params">(wait_for_data())</span></span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">pop_head</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">std::unique_ptr&lt;node&gt; <span class="title">wait_pop_head</span><span class="params">(T&amp; value)</span></span>&#123;</span><br><span class="line">    <span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">head_lock</span><span class="params">(wait_for_data())</span></span>;</span><br><span class="line">    value = std::<span class="built_in">move</span>(*head -&gt; data);</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">pop_head</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">std::unique_ptr&lt;node&gt; <span class="title">try_pop_head</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">head_lock</span><span class="params">(head_mutex)</span></span>;</span><br><span class="line">    <span class="keyword">if</span>(head.<span class="built_in">get</span>() == <span class="built_in">get_tail</span>())</span><br><span class="line">        <span class="keyword">return</span> std::<span class="built_in">unique_ptr</span>&lt;node&gt;();</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">pop_head</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">std::unique_ptr&lt;node&gt; <span class="title">try_pop_head</span><span class="params">(T&amp; value)</span></span>&#123;</span><br><span class="line">    <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">head_lock</span><span class="params">(head_mutex)</span></span>;</span><br><span class="line">    <span class="keyword">if</span>(head.<span class="built_in">get</span>() == <span class="built_in">get_tail</span>())</span><br><span class="line">        <span class="keyword">return</span> std::<span class="built_in">unique_ptr</span>&lt;node&gt;();</span><br><span class="line">    value = std::<span class="built_in">move</span>(*head -&gt; data);</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">pop_head</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里实现了一些辅助函数来完成实现，但主要还是需要注意两个锁的上锁位置和上锁顺序，在保证安全的前提下尽可能短时间的持有锁。</p><h1 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h1><p>map不同于前两种数据结构，通常我们不需要对map有太多的修改，而是有大量的查询操作。但是tls库中提供的一些map都不是线程安全的。而且考虑这样一个问题，如果一个map返回了一个迭代器，像tls库中提供的那样，那么这个迭代器指向的数据被删除时，所有对这个迭代器的访问都是未定义的。</p><p>我们对map定义四种接口：添加，修改，删除和查询。</p><p>这里我们还是考虑使用细粒度的锁来实现我们的数据结构。实现map共有三种方法，红黑树、有序数组和哈希表，前两种方法都无法细粒度化锁或者说无法彻底细粒度化，所以考虑使用哈希表实现。使用哈希表时我们可以安心的对每个桶上锁</p><p>接口如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Key, <span class="keyword">typename</span> Value, <span class="keyword">typename</span> Hash = std::hash&lt;Key&gt; &gt;</span><br><span class="line"><span class="keyword">class</span> threadsafe_lookup_table&#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">class</span> bucket_type&#123;</span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="keyword">typedef</span> std::pair&lt;Key, Value&gt; bucket_value;</span><br><span class="line">        <span class="keyword">typedef</span> std::list&lt;bucket_value&gt; bucket_data;</span><br><span class="line">        <span class="keyword">typedef</span> <span class="keyword">typename</span> bucket_data::iterator bucket_iterator;</span><br><span class="line"></span><br><span class="line">        bucket_data data;</span><br><span class="line">        <span class="keyword">mutable</span> std::shared_mutex mutex;</span><br><span class="line"></span><br><span class="line">        <span class="function">bucket_iterator <span class="title">find_entry_for</span><span class="params">(Key <span class="type">const</span>&amp; key)</span> <span class="type">const</span></span></span><br><span class="line"><span class="function">    <span class="keyword">public</span>:</span></span><br><span class="line"><span class="function">        Value value_for(Key const&amp; key, Value const&amp; default_value) const;</span></span><br><span class="line">        <span class="function"><span class="type">void</span> <span class="title">add_or_update_mapping</span><span class="params">(Key <span class="type">const</span>&amp; key, Value <span class="type">const</span>&amp; value)</span></span>;</span><br><span class="line">        <span class="function"><span class="type">void</span> <span class="title">remove_mapping</span><span class="params">(Key <span class="type">const</span>&amp; key)</span></span>;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    std::vector&lt;std::unique&lt;bucket_type&gt; &gt; buckets;</span><br><span class="line">    Hash hasher;</span><br><span class="line">    <span class="function">bucket_type&amp; <span class="title">get_bucket</span><span class="params">(Key <span class="type">const</span>&amp; key)</span> <span class="type">const</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span>:</span></span><br><span class="line"><span class="function">    typedef Key key_type;</span></span><br><span class="line">    <span class="keyword">typedef</span> Value mapped_type;</span><br><span class="line">    <span class="keyword">typedef</span> Hash hash_type;</span><br><span class="line"></span><br><span class="line">     <span class="built_in">threadsafe_lookup_table</span>(<span class="type">unsigned</span> num_buckets = <span class="number">19</span>, Hash <span class="type">const</span>&amp; hasher_ = <span class="built_in">Hash</span>()) :</span><br><span class="line">        <span class="built_in">buckets</span>(num_buckets), <span class="built_in">hasher</span>(hasher_)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">unsigned</span> i = <span class="number">0</span>; i &lt; num_buckets; ++i)</span><br><span class="line">                buckets[i].<span class="built_in">reset</span>(<span class="keyword">new</span> bucket_type);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">threadsafe_lookup_table</span>(threadsafe_lookup_table <span class="type">const</span>&amp; other) = <span class="keyword">delete</span>;</span><br><span class="line">    threadsafe_lookup_table&amp; <span class="keyword">operator</span>=(threadsafe_lookup_table <span class="type">const</span>&amp; other) = <span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">Value <span class="title">value_for</span><span class="params">(Key <span class="type">const</span>&amp; key, Value <span class="type">const</span>&amp; default_value = Value())</span> <span class="type">const</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">add_or_update_mapping</span><span class="params">(Key <span class="type">const</span>&amp; key, Value <span class="type">const</span>&amp; value)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">remove_mapping</span><span class="params">(Key <span class="type">const</span>&amp; key)</span></span>;</span><br><span class="line">    <span class="function">std::map&lt;Key, Value&gt; <span class="title">get_map</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接口的定义已经非常清晰了。在构造函数中我们可以指定桶的数量，这个数通常是一个质数，因为这样会使哈希表的工作效率最高，在《算法导论》这本书中可以找到相关的证明。每个桶都会被一个std::shared_mutex保护，所以对每个桶来说，只有一个线程可以修改他。</p><p>这里的get_bucket()是无需上锁的，因为他不会修改任何数据，而且桶的数量是固定的。value_for()不会对数据进行修改，只进行查询操作，所以可以只获得读锁。get_map()用于生成当前状态的快照，该操作需要获取每个桶的锁，也就是锁住整个map（这里有更加高效的实现！）。</p><h1 id="List"><a href="#List" class="headerlink" title="List"></a>List</h1><p>前面的map使用了stl库中的list进行实现，那么它是线程安全的吗？不是。线程安全的链表需要提供以下接口：添加、删除、查找、更新和复制。链表是天然的可以高效并发的数据结构，我们可以让每个节点持有一个互斥量，这样我们就可以对持有的节点群上锁，并在移动到下一个节点时对锁进行释放。</p><p>接口如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">threadsafe_list</span>&#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">node</span>&#123;</span><br><span class="line">        std::shared_ptr&lt;T&gt; data;</span><br><span class="line">        std::unique_ptr&lt;T&gt; next;</span><br><span class="line">        std::mutex m;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">node</span>(): <span class="built_in">next</span>() &#123;&#125;</span><br><span class="line">        <span class="built_in">node</span>(T <span class="type">const</span>&amp; value): <span class="built_in">data</span>(std::<span class="built_in">make_shared</span>&lt;T&gt;(value))&#123;&#125;;</span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line">    node head;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">threadsafe_list</span>()&#123;&#125;</span><br><span class="line">    ~<span class="built_in">threadsafe_list</span>()&#123;</span><br><span class="line">        std::<span class="built_in">remove_if</span>([](T <span class="type">const</span>&amp;)&#123;<span class="keyword">return</span> <span class="literal">true</span>;&#125;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">threadsafe_list</span>(threadsafe_list <span class="type">const</span>&amp; other)=<span class="keyword">delete</span>;</span><br><span class="line">    threadsafe_list&amp; <span class="keyword">operator</span>=(threadsafe_list <span class="type">const</span>&amp; other)=<span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">push_front</span><span class="params">(T <span class="type">const</span>&amp; value)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Function&gt; <span class="type">void</span> <span class="title">for_each</span><span class="params">(Function f)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Predicate&gt; std::shared_ptr&lt;T&gt; <span class="title">find_first_if</span><span class="params">(Predicate p)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Predicate&gt; <span class="type">void</span> <span class="title">remove_if</span><span class="params">(Predicate p)</span></span></span><br><span class="line"><span class="function">&#125;</span>;</span><br></pre></td></tr></table></figure><p>这里是一个单链表的实现。</p><blockquote><p><strong>为什么不使用标准库中的实现（for_each、remove_if和find_first_if）</strong><br>因为stl类的迭代器是需要持有容器内部引用的，这可能会导致在无锁状态下对数据结构产生修改，所以使用自定义的函数。</p></blockquote><p>链表中的加锁和解锁是一个手递手的过程就像下面这样：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Predicate&gt;</span></span><br><span class="line"><span class="function">std::shared_ptr&lt;T&gt; <span class="title">find_first_if</span><span class="params">(Predicate p)</span></span>&#123;</span><br><span class="line">    node* current = &amp;head;</span><br><span class="line">    <span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">lk</span><span class="params">(head.m)</span></span>;</span><br><span class="line">    <span class="keyword">while</span>(node* <span class="type">const</span> next=current-&gt;next.<span class="built_in">get</span>())&#123;</span><br><span class="line">        <span class="function">std::unique_lock&lt;std::mutex&gt; <span class="title">next_lk</span><span class="params">(next-&gt;m)</span></span>;</span><br><span class="line">        lk.<span class="built_in">unlock</span>();</span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">p</span>(*next-&gt;data))&#123;</span><br><span class="line">            <span class="keyword">return</span> next-&gt;data;</span><br><span class="line">        &#125;</span><br><span class="line">        current=next;</span><br><span class="line">        lk=std::<span class="built_in">move</span>(next_lk);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> std::<span class="built_in">shared_ptr</span>&lt;T&gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们持有下一个节点的锁，释放这个节点的锁，以此类推。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>写的太过简陋，大家还是去看看代码吧，可以更深入的了解。当然也可以通过内存序来实现无锁结构的线程安全的数据结构，可以参考其它资料。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本文将介绍一些c++中基于锁实现的并发数据结构。包括线程安全的Stack、Queue、List和Map。本文代码主要基于c++14，有时也会使用一些c++17和c++20的新特性，同时会使用到一些基本的特性和并发开发工具，文中不会详细介绍，建议查阅资料或书籍《c++并发编程</summary>
      
    
    
    
    <category term="c++" scheme="https://peacill.online/categories/c/"/>
    
    
    <category term="c++" scheme="https://peacill.online/tags/c/"/>
    
    <category term="Concurrnecy" scheme="https://peacill.online/tags/Concurrnecy/"/>
    
  </entry>
  
  <entry>
    <title>Raft: A Understandable Consensus Algorithm</title>
    <link href="https://peacill.online/post/9989.html"/>
    <id>https://peacill.online/post/9989.html</id>
    <published>2024-12-25T07:22:00.000Z</published>
    <updated>2024-12-26T13:15:55.552Z</updated>
    
    <content type="html"><![CDATA[<p>本文将详细介绍Raft共识算法。</p><p>论文参考：<a href="https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf">《In Search of an Understandable Consensus Algorithm》</a></p><p>&emsp;&emsp;Raft是一种用于管理复制日志的共识算法，其设计目标是提高可理解性。Raft通过分解共识的关键元素，如领导者选举、日志复制和安全性，来增强可理解性。它采用强领导者机制，确保日志条目仅从领导者流向其他服务器，从而简化了复制日志的管理。领导者选举使用随机定时器，快速解决冲突。Raft还引入了一种新的集群成员变更机制，利用重叠多数来保证安全性，使得在配置变化期间集群能够正常运行。总的来说，Raft提供了一个简单易懂且有效的共识算法基础，适合在生产环境中应用。</p><h1 id="状态机复制"><a href="#状态机复制" class="headerlink" title="状态机复制"></a>状态机复制</h1><p>&emsp;&emsp;复制状态机是分布式系统中解决容错问题的重要方法。在这种方法中，多个服务器上的状态机计算相同的状态副本，即使部分服务器发生故障，系统仍能继续运行。许多大规模系统如GFS、HDFS和RAMCloud都使用复制状态机来管理领导者选举和存储配置信息。</p><p>&emsp;&emsp;复制状态机通常通过复制日志来实现。每个服务器存储包含一系列命令的日志，这些命令按顺序被状态机执行。由于所有日志包含相同顺序的相同命令，且状态机是确定性的，因此每个状态机都会计算出相同的状态和输出序列。共识算法的任务就是保持复制日志的一致性。复制状态机的实现如下图所示：<br><img src="/img/blog/Raft/raft_1.jpg" alt="复制状态机"><br>复制状态机环境下的用户请求执行流程如下：</p><ol><li>客户端向服务器的共识模块发送命令请求。</li><li>共识模块将接收到的命令添加到日志中，并与其他服务器的共识模块通信以确保日志复制的一致性。</li><li>一旦命令被正确复制，服务器的状态机按照日志顺序处理这些命令，更新状态（如图中显示的x、y、z变量值）。</li><li>最后，处理结果返回给客户端。</li></ol><p>整个流程确保了所有服务器上的状态机都能按相同顺序执行相同的命令序列，从而维持系统状态的一致性。（图中的多层服务器表示这是一个分布式系统，每个服务器都包含相同的组件结构）。</p><p>生产环境中的共识算法具有以下特性：</p><ul><li>在所有非拜占庭条件下（包括网络延迟、分区和数据包丢失、重复和重排序）确保安全性；</li><li>只要大多数服务器正常运行并能相互通信，系统就能保持完全功能；</li><li>不依赖时序来确保日志一致性；</li><li>在常见情况下，只需集群中大多数节点响应单轮远程过程调用（RPC），命令就能完成执行。</li></ul><h1 id="Raft算法"><a href="#Raft算法" class="headerlink" title="Raft算法"></a>Raft算法</h1><p>&emsp;&emsp;Raft设计初衷中最重要的一点便是它的可理解性（作者不希望Raft像Paxos那样难以理解，同时存在算法描述和实现不一致的问题）。为了提高算法的可理解性，主要引入了以下两点改进：</p><ul><li>分解问题：Raft将leader选取、日志复制、安全性和关系专业分为独立的部分处理，分解问题的复杂度。</li><li>缩小状态空间：通过减少状态的数量缩小状态空间，使系统更加连贯，并尽可能的消除不确定性。</li></ul><p>&emsp;&emsp;Raft算法的实现首先会选举一个leader，这个leader负责从client哪里接收日志条目，并复制到其他的server。鉴于使用了leader，Raft把共识问题分为了三个小问题分别是：</p><ol><li>leader的选举：当当前leader损坏时，必须重新选取leader</li><li>日志的复制：leader负责将从client哪里接收的日志条目通过集群复制到其他的server</li><li>安全性：Raft保证在任何时候，下图中的安全性均适用：<br><img src="/img/blog/Raft/raft_2.jpg" alt="Raft安全性"></li></ol><p>Raft算法全貌如下：<br><img src="/img/blog/Raft/raft_3.jpg" alt="Raft算法全貌"></p><h2 id="Raft算法基础"><a href="#Raft算法基础" class="headerlink" title="Raft算法基础"></a>Raft算法基础</h2><h3 id="服务器状态"><a href="#服务器状态" class="headerlink" title="服务器状态"></a>服务器状态</h3><p>&emsp;&emsp;Raft服务器共有三种状态：leader（领导者）、follower（追随者）和candidate（候选人），在通常情况下，只有一个leader，它负责处理所有的client请求，其它都是follower。当一个follower收不到来自leader的日志条目时，他会发起投票，并成为一个candidate。一个leader一般会一直运行知道它失败。服务器之间的状态转换图如下：<br><img src="/img/blog/Raft/raft_4.jpg" alt="服务器之间的状态转换图"></p><h3 id="任期（terms）"><a href="#任期（terms）" class="headerlink" title="任期（terms）"></a>任期（terms）</h3><p>&emsp;&emsp;Raft将时间划分为任意长度的任期（term），如下图，每个任期以选举开始。在选举中，一个或多个candidate尝试成为leader。如果candidate赢得选举，则在该任期内担任leader；若选举出现平票，则该任期无leader，随后进入新任期并重新选举。Raft保证每个任期最多只有一个leader。各服务器可能在不同时间观察到任期的变化，有时甚至可能错过整个任期。任期作为逻辑时钟，用于检测过时信息（如失效的leader）。每个服务器存储当前的任期号，并在通信时交换。如果发现自己的任期号落后，会更新为较大的值；candidate或leader若发现自己任期过时，会立即退回到follower状态。对于带有过时任期号的请求，服务器会拒绝处理。<br><img src="/img/blog/Raft/raft_5.jpg" alt="任期"><br>&emsp;&emsp;Raft通过远程过程调用（RPC）进行通信，核心算法使用两种RPC：candidate在选举期间发起的RequestVote RPC，以及leader用于日志复制和发送心跳的AppendEntries RPC。</p><h2 id="leader选举"><a href="#leader选举" class="headerlink" title="leader选举"></a>leader选举</h2><p>&emsp;&emsp;Raft通过心跳机制触发leader选举。当服务器启动时，初始状态为follower，只要收到来自leader或candidate的有效RPC，便保持follower状态。leader通过定期发送心跳消息（不包含日志条目的AppendEntries RPC）维持其权威性。如果follower在选举超时时间内未收到leader的RPC，则它认为当前没有有效的leader，并发起选举。</p><p>&emsp;&emsp;选举开始时，follower增加当前任期号并转为candidate状态，同时投自己一票后向集群中其他服务器并行发送RequestVote RPC。candidate会持续等待投票结果，直到以下三种情况之一发生：</p><ul><li>赢得选举（成功）：若candidate获得集群中多数服务器的投票，则赢得选举并成为leader，然后向其他服务器发送心跳以确立权威，来防止新一轮选举。</li><li>另一个服务器成为leader（失败）：如果candidate在等待投票期间收到来自另一个leader的AppendEntries RPC，且该RPC的任期号不小于自身的当前任期号，则承认对方为合法leader并退回到follower状态；否则（自己的任期号要大）的话，拒绝该RPC并继续保持candidate状态。</li><li>没有获胜者（平票）：若多个follower同时成为candidate且票数近乎平分，导致没有候选人获得多数票，则每个candidate会超时后增加任期号并重新发起选举。</li></ul><p>&emsp;&emsp;为减少平分投票的发生，Raft中的每个server都会设置一个随机化的选举超时时间（如150-300ms），这使得大多数情况下只有一个服务器超时并发送RequestVote RPC，他大概率会成功当选leader。即使出现平分投票的情况，随机化超时机制也能快速解决问题，每个服务器会设定随机的时间，并等待这个时间后再次成为candidate。</p><h2 id="日志复制"><a href="#日志复制" class="headerlink" title="日志复制"></a>日志复制</h2><p>&emsp;&emsp;领导者被选举后，会负责处理客户端请求。每个请求都包含需要在复制服务器的状态机上执行的命令。领导者会将命令追加到自己的日志中，并通过AppendEntries RPC并行通知其他服务器复制该条目。一旦确认该条目被安全地复制到大多数服务器上，领导者就会将该命令应用到自己的状态机，并将执行结果返回给客户端。</p><p>&emsp;&emsp;日志的组织结构非常严谨，每个日志条目都存储了状态机命令以及领导者接收到该条目时的任期编号。这些任期编号用于检测日志之间的不一致性，同时确保日志具有某些重要特性。每个日志条目还包含一个整数索引，用于标识其在日志中的位置。日志结构如下图所示：<br><img src="/img/blog/Raft/raft_6.jpg" alt="日志结构"><br>只要领导者将一条日志复制到大多数的服务器上，那么这条日志就会被提交，如图中的日志7，之前的所有日志都会是被提交的状态。</p><p>Raft通过以下两个特性来保证日志的一致性：</p><ul><li>如果不同日志中的两个条目具有相同的索引和任期，则它们存储相同的命令</li><li>如果不同日志中的两个条目具有相同的索引和任期，则之前的所有日志条目都相同</li></ul><p>当出现领导者崩溃时，可能会导致日志不一致的情况。如下图所示：<br><img src="/img/blog/Raft/raft_7.jpg" alt="日志不一致"><br>图中的每个框都表示一条日志，框中的数字代表任期（term）， follower可能缺少条目 (a–b)，可能有额外的未提交条目 (c–d)，或两者都有 (e–f)。例如，如果f服务器是第2任期的领导者，向其日志添加了多个条目，然后在提交其中任何条目之前崩溃，则可能会出现场景 (f)；它很快重新启动，成为第3任期的领导者，并在其日志中添加了更多条目；在提交第2任期或第3任期中的任何条目之前，服务器再次崩溃并在后面的几个任期内保持关闭状态。</p><p>&emsp;&emsp;新的领导者会通过强制跟随者复制自己的日志来解决这种不一致。具体来说，领导者会找到自己与跟随者日志中最新的共同条目，删除跟随者在该点之后的所有条目，然后将自己在该点之后的所有条目发送给跟随者。为了实现这个机制，领导者会为每个跟随者维护一个nextIndex值，表示下一个要发送给该跟随者的日志条目的索引。当新领导者上任时，它会将所有nextIndex初始化为自己最后一个日志条目的下一个位置，并发送AppendEntries RPC。如果发现跟随者的日志与自己不一致，领导者会通过递减nextIndex并重发RPC的方式，最终找到两者的日志匹配点。</p><p>&emsp;&emsp;这种日志复制机制具有良好的容错性和性能特征。只要集群中的多数服务器正常运行，系统就能继续工作。在正常情况下，新的日志条目只需要一轮RPC就能复制到集群的多数节点上。而且，单个慢速跟随者不会影响整体性能。领导者永远不会覆盖或删除自己的日志条目，这保证了系统的安全性。通过这种设计，Raft能够在保证安全性的同时提供良好的性能，使其成为一个实用的分布式共识算法。即使在网络不稳定或服务器故障的情况下，系统也能保持正确运行并最终达成一致。</p><h2 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h2><p>&emsp;&emsp;前面介绍了Raft算法如何选举领导者和复制日志条目。然而，这些机制还不足以确保每个状态机都能按照完全相同的顺序执行相同的命令。这是因为可能会出现一些特殊情况，导致系统的一致性被破坏。</p><p>&emsp;&emsp;举个例子，假设一个跟随者在领导者提交多个日志条目的时候处于离线状态。如果这个跟随者后来被选举为新的领导者，它可能会用新的条目覆盖那些已经提交的条目。这就会导致不同的状态机执行了不同的命令序列，破坏了系统的一致性。为了解决这个问题，Raft算法对哪些服务器可以被选举为领导者增加了限制条件。这个限制确保了在任何给定任期内，被选举的领导者都必须包含之前任期中所有已提交的条目。这就是所谓的领导者完整性特性。有了这个选举限制，Raft算法进一步完善了提交规则，使其更加精确。</p><h3 id="选举限制"><a href="#选举限制" class="headerlink" title="选举限制"></a>选举限制</h3><p>&emsp;&emsp;Raft通过选举限制确保新领导者从一开始就包含之前任期的所有已提交条目。这意味着日志条目只能从领导者单向流向跟随者，领导者永远不会覆盖自己日志中已存在的条目。</p><p>&emsp;&emsp;为了实现这一点，Raft在投票过程中加入了限制条件。候选人必须联系集群中的多数节点才能当选，这意味着每个已提交的条目必定存在于这些服务器中的至少一个。如果候选人的日志至少与多数派中的任何其他日志一样新，那么它就包含了所有已提交的条目。在RequestVote RPC中实现了这个限制：请求中包含候选人的日志信息，如果投票者发现自己的日志比候选人的更新，就会拒绝投票。Raft通过比较日志最后条目的索引和任期来判断两个日志的新旧程度：</p><ul><li>如果最后条目的任期不同，任期更大的日志更新</li><li>如果最后条目的任期相同，则更长的日志更新</li></ul><p>这种机制确保了系统的安全性，防止了已提交条目被覆盖的问题。</p><h3 id="提交以前任期的日志条目"><a href="#提交以前任期的日志条目" class="headerlink" title="提交以前任期的日志条目"></a>提交以前任期的日志条目</h3><p>&emsp;&emsp;在Raft中，领导者一旦确认其当前任期的日志条目在大多数服务器上存储，就可以认为该条目已提交。这意味着只要有超过一半的服务器成功接收并存储了这个条目，领导者就可以安全地将其视为已提交，并将其应用到状态机中。然而，对于来自之前任期的日志条目，仅仅因为它们在大多数服务器上存储，领导者并不能立即得出这些条目已提交的结论。比如下图所示的情况：<br><img src="/img/blog/Raft/raft_8.jpg" alt="旧日志条目"></p><ul><li>步骤 (a)：S1作为领导者，部分复制了索引为2的日志条目。</li><li>步骤 (b)：S1崩溃，S5在第3任期被选为领导者，获得来自S3、S4及自身的投票，并收到了不同的索引为2的日志条目，此时S5崩溃。</li><li>步骤 (c)：S5崩溃后，S1重新启动并被选为领导者，继续进行日志复制。此时，第2任期的日志条目已在大多数服务器上复制，但尚未提交。</li><li>步骤 (d)：如果S1再次崩溃，S5可能会被选为领导者（获得来自S2、S3和S4的投票），并用其第3任期的条目覆盖之前的条目</li><li>步骤 (e)：如果S1在崩溃之前，已将把当前任期的条目复制到大多数服务器上，则该条目被视为已提交（此时S5无法赢得选举）。此时，所有之前的日志条目也被视为已提交。</li></ul><p>图中展示了一个旧的日志条目在大多数服务器上存储，但仍然可能被未来的新领导者覆盖。这种情况可能导致不同的状态机执行不同的命令序列，从而破坏系统的一致性。</p><p>&emsp;&emsp;为了避免上述问题，Raft不通过计数副本来提交之前任期的日志条目。只有当前任期的日志条目在确认复制后才会被提交。一旦当前任期的条目被提交，根据日志匹配特性，所有之前的条目也会间接地被认为是已提交。这种设计确保了即使旧条目在多数服务器上存在，也不会被错误地认为是已提交。Raft引入了额外复杂性，因为它在复制过程中保留了日志条目的原始任期编号。在其他共识算法中，当新领导者重新复制之前“任期”的条目时，通常会使用新的“任期编号”。而Raft的方法则使得对日志条目的推理变得更简单，因为这些条目在时间和不同日志中保持相同的任期编号。此外，与其他算法相比，Raft的新领导者发送来自之前任期的日志条目的数量更少。其他算法需要发送冗余的日志条目以重新编号，然后才能进行提交，而Raft则避免了这种冗余，从而提高了效率。</p><h3 id="leader完整性的成立"><a href="#leader完整性的成立" class="headerlink" title="leader完整性的成立"></a>leader完整性的成立</h3><p>&emsp;&emsp;原文中通过一个反证法证明了leader的完整性，同时鉴于leader完整性的成立，状态机的完整性也得到了证明。想了解证明过程可以去看看原文，证明过程也比较简单明了。</p><blockquote><p> <strong>leader完整性：</strong>领导者完整性特性确保在任期T的领导者（leaderT）提交的日志条目，未来任期的任何领导者（例如任期U的leaderU）都必须包含这些已提交的条目。</p></blockquote><p>所以在上面那张图中的步骤（d）是不会发生的，也就是是说以前任期复制但未提交的条目不会被覆盖。</p><blockquote><p><strong>状态机完整性：</strong></p><ol><li>日志一致：当一个服务器将日志条目应用到其状态机时，该服务器的日志必须与领导者的日志在该条目之前完全相同，并且该条目必须是已提交的。这意味着该条目已经被大多数服务器接受并存储。</li><li>最低任期的考虑：考虑任何服务器在某个给定日志索引上应用日志条目的最低任期。根据领导者完整性特性，所有更高任期的领导者都会存储相同的日志条目。因此，在后续任期中应用该索引的服务器也会应用相同的值。</li><li>有序应用：Raft要求所有服务器按照日志索引顺序应用条目。这意味着所有服务器都将以相同的顺序将相同的日志条目应用到其状态机中。</li></ol></blockquote><p>综上，通过leader一致性，Raft确保了状态机安全性特性，即所有服务器在相同的日志索引上应用相同的日志条目，从而保证了系统的一致性和可靠性。</p><h2 id="follower和candidate的失败"><a href="#follower和candidate的失败" class="headerlink" title="follower和candidate的失败"></a>follower和candidate的失败</h2><p>&emsp;&emsp;当一个跟随者或候选者崩溃时，未来发送给它们的RequestVote和AppendEntries RPC将会失败。Raft通过无限重试来应对这些失败；如果崩溃的服务器重新启动，这些RPC请求将成功完成。如果服务器在完成RPC请求后崩溃但尚未响应，重新启动后它会再次接收到相同的RPC请求。Raft的RPC设计为幂等性，这意味着重复接收相同请求不会造成任何问题。例如，当一个跟随者收到包含已存在日志条目的AppendEntries请求时，它会忽略新请求中的这些条目。</p><h2 id="时序和可用性"><a href="#时序和可用性" class="headerlink" title="时序和可用性"></a>时序和可用性</h2><p>&emsp;&emsp;领导者选举是Raft中对时间要求最为关键的方面。Raft能够选举并维持稳定的领导者，只要满足以下时间要求：<br><strong><p style="text-align: center;">broadcastTime &lt;&lt; electionTimeout&lt;&lt; MTBF</p></strong></p><p>其中，broadcastTime是服务器并行发送RPC并接收响应的平均时间；electionTimeout是选举超时；MTBF是单个服务器的平均故障间隔。广播时间应比选举超时小一个数量级，以便领导者能够可靠地发送心跳消息，防止跟随者启动选举。同时，这种不等式也降低了出现平票的可能性。选举超时应比MTBF小几个数量级，以确保系统持续进展。在通常情况下，broadcastTime可能在0.5毫秒到20毫秒之间，因此，electionTimeout很可能在10毫秒到500毫秒之间。典型服务器的MTBF通常为几个月或更长。所以这个要求很好满足。</p><h1 id="集群重配"><a href="#集群重配" class="headerlink" title="集群重配"></a>集群重配</h1><p>&emsp;&emsp;在一些情况下，我们需要重新配置整个集群，如有新的服务器加入，这是停止服务等待配置完成后再启动服务会导致服务的停止，从而影响真个系统的可用性。所以，Raft采用了自动配置的方法。</p><p>&emsp;&emsp;在集群配置变更的过程中，Raft共识算法采用了两阶段的方法以确保系统的安全性，避免在过渡期间出现两个领导者被选出的情况。直接从旧配置切换到新配置是不安全的，因为无法实现所有服务器的原子切换，这可能导致集群分裂成两个独立的多数派。如下图：<br><img src="/img/blog/Raft/raft_9.jpg" alt="集群分裂"><br>如图所示，在新配置和旧配置交织的阶段可能会出现两个leader同时领导集群的情况。</p><p>&emsp;&emsp;因此，Raft引入了一个过渡状态，称为联合共识（joint consensus），以确保在变更过程中集群仍能处理客户端请求。集群重配流程图如下：<br><img src="/img/blog/Raft/raft_10.jpg" alt="集群重配流程图"><br>图中展示了更改配置的时间线，具体流程如下：</p><ol><li>创建配置条目：领导者首先在日志中创建C(old,new)配置条目，但此时尚未提交。</li><li>提交联合共识：领导者将C(old,new)条目提交给C(old)和C(new)的多数派。这意味着在这一阶段，旧配置（C(old)）和新配置（C(new)）共同参与决策。</li><li>创建新配置条目：一旦C(old,new)被提交，领导者接着创建C(new)条目，并将其提交给C(new)的多数派。</li></ol><p>整个过程中，C(old)和C(new)没有任何时刻可以独立做出决策，从而确保了系统的安全性和一致性。</p><p>联合共识的工作机制如下：</p><ul><li>日志条目存储与复制：当领导者接收到变更配置的请求时，会将联合共识的配置（包括旧配置和新配置）存储为日志条目并进行复制。所有服务器在日志中记录最新配置，并根据该配置进行决策。</li><li>决策规则：在联合共识阶段，任何来自旧配置或新配置的服务器都可以成为领导者。对于选举和日志条目的提交，需要分别获得旧配置和新配置的多数同意。这意味着在这一阶段，集群可以继续正常服务，而不会因为配置变更而中断。</li><li>安全性保障：在提交新配置日志条目之前，领导者会确保不会允许任何一方单方面做出决策，从而保证了系统的安全性。一旦联合共识被提交，旧配置和新配置都需要相互批准才能进行决策。</li></ul><p>为了进一步优化集群的可用性，Raft还考虑了以下几个问题：</p><ol><li>新服务器加入：新服务器在加入集群时可能没有存储任何日志条目，这可能导致它们需要较长时间才能赶上其他服务器。为了解决这个问题，新服务器会作为非投票成员加入集群，领导者会将日志条目复制给它们，但这些新服务器不会被计算在多数派中。一旦它们赶上其他服务器，就可以开始一次配置变更，让他们真正的加入集群，并拥有投票权。</li><li>领导者不在新配置中：如果当前领导者不在新的配置中，它会在提交新配置日志条目后降级为跟随者状态。在此期间，领导者仍然负责复制日志条目，但不再计算自己在多数派中，这样可以确保新配置能够独立运作。</li><li>移除服务器的干扰：被移除的服务器可能会对集群造成干扰，因为它们无法接收到心跳消息，会超时并发起新的选举。为了防止这种情况，Raft规定服务器在认为当前存在领导者时（没有达到最小的选举超时时间），会忽略来自这些移除服务器的投票请求。这种机制确保了只要当前领导者能够向集群发送心跳信号，就不会被较大的任期号所取代，从而保持集群的稳定性和可用性。</li></ol><h1 id="日志压缩——快照"><a href="#日志压缩——快照" class="headerlink" title="日志压缩——快照"></a>日志压缩——快照</h1><p>&emsp;&emsp;Raft的日志在正常操作中会不断增长，以记录更多的客户端请求，但日志不能无限制地增长。随着日志的增加，它占用的空间和重放所需的时间也会增加，这可能导致可用性问题。因此，需要一种机制来丢弃日志中积累的过时信息。</p><p>&emsp;&emsp;快照是最简单的压缩方法。在快照过程中，当前系统状态被写入稳定存储中，然后丢弃到该点为止的整个日志。Raft中的快照机制允许每个服务器独立地进行快照，只覆盖其日志中已提交的条目。</p><p>Raft的日志结构如下图：<br><img src="/img/blog/Raft/raft_11.jpg" alt="日志结构"><br>图中日志经存储已提交条目点之前的最终状态，图中快照建立时的日志index为5，所以最后的状态为x &lt;- 0, y &lt;- 9，这样根据日志，系统就可以恢复到index为6前的最终状态。日志中还包含一些其它的信息例如：最后一个日志条目的索引和其任期，保留这些是为了支持快照后第一个日志条目的 AppendEntries 一致性检查。同时，日志中还需要包含截止当前的最新配置，来支持集群的重配。</p><p>&emsp;&emsp;领导者需要向滞后的跟随者发送快照，尤其是在领导者已经丢弃了需要发送给跟随者的下一个日志条目时。领导者使用新的RPC（InstallSnapshot）将快照发送给滞后的跟随者。InstallSnapshot RPC如下图所示：<br><img src="/img/blog/Raft/raft_12.jpg" alt="InstallSnapshot RPC"><br>跟随者在接收到快照后，需要决定如何处理现有的日志条目。如果快照包含新的信息，通常会丢弃整个日志；如果快照描述的是其日志的前缀，则仅删除被快照覆盖的条目，保留后续条目。</p><p>&emsp;&emsp;在进行快照时，服务器需要决定何时进行快照。如果频繁快照，会浪费磁盘带宽和能量；如果不够频繁，则可能耗尽存储容量并增加重启时重放日志所需的时间。一种简单策略是当日志达到固定字节大小时进行快照。此外，写入快照可能需要很长时间，因此使用写时复制技术（copy-on-write）（例如Linux中的fork便采用了写时复制技术）以便可以接受新的更新而不影响正在写入的快照。</p><h1 id="客户端同Raft的交互"><a href="#客户端同Raft的交互" class="headerlink" title="客户端同Raft的交互"></a>客户端同Raft的交互</h1><p>&emsp;&emsp;客户端如何与集群进行交互，特别是如何找到集群的领导者以及如何支持线性化语义？</p><h2 id="客户端寻找领导者"><a href="#客户端寻找领导者" class="headerlink" title="客户端寻找领导者"></a>客户端寻找领导者</h2><p>&emsp;&emsp;客户端将所有请求发送给领导者。当客户端启动时，会随机连接到一个服务器。如果该服务器不是领导者，它会拒绝请求并提供最新领导者的信息（AppendEntries RPC中会包含leader的RPC）。如果领导者崩溃，客户端请求会超时，随后客户端会尝试与其他随机选择的服务器重新连接。</p><h2 id="线性化语义"><a href="#线性化语义" class="headerlink" title="线性化语义"></a>线性化语义</h2><p>&emsp;&emsp;Raft旨在实现线性化语义，即每个操作看起来在某个时间点瞬时执行且只执行一次。然而，由于领导者可能崩溃，导致命令被重复执行（如在leader回复客户端时崩溃，那么客户端会重新请求，已经被执行过一次的日志条目会被再执行一遍，并将结果返回给客户端），因此需要为每个命令分配唯一的序列号。状态机会跟踪每个客户端处理的最新序列号及其响应。如果接收到的命令序列号已被处理，则立即返回响应，而不重新执行请求（这是一个只读的请求）。</p><p>&emsp;&emsp;对于只读操作，Raft可以在不写入日志的情况下处理，但可能会返回过时数据（leader更新）。为了保证线性化读取不返回过时数据，Raft采取了两项额外措施：首先，领导者必须了解哪些条目已被提交，Raft通过在领导者任期开始时提交一个空的无操作条目来解决此问题；其次，领导者在处理只读请求之前必须检查自己是否被取代（新leader当选，则信息过时），以确保信息不陈旧，这通过与大多数集群成员交换心跳消息来实现。通过这些机制，Raft能够有效地管理客户端请求并保持一致性。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>&emsp;&emsp;在本文中，我们深入探讨了Raft共识算法的核心概念及其在分布式系统中的重要性。Raft通过明确的领导者选举、日志复制和安全性机制，提供了一种易于理解且高效的方式来实现一致性。总而言之，Raft不仅是一种强大的共识算法，它还通过清晰的设计和实现，使得开发者能够轻松理解和应用这一技术。在现代分布式系统中，Raft为数据一致性和可靠性提供了坚实的基础，成为许多开源项目和商业应用的重要组成部分。随着对分布式计算需求的不断增长，Raft无疑将在未来继续发挥关键作用。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本文将详细介绍Raft共识算法。&lt;/p&gt;
&lt;p&gt;论文参考：&lt;a href=&quot;https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf&quot;&gt;《In Search of an Understandable Consensu</summary>
      
    
    
    
    <category term="Distributed" scheme="https://peacill.online/categories/Distributed/"/>
    
    
    <category term="Consensus Algorithm" scheme="https://peacill.online/tags/Consensus-Algorithm/"/>
    
    <category term="Distribute" scheme="https://peacill.online/tags/Distribute/"/>
    
  </entry>
  
  <entry>
    <title>VMware FT: Practical System for Fault-Tolerant Virtual Machines</title>
    <link href="https://peacill.online/post/42123.html"/>
    <id>https://peacill.online/post/42123.html</id>
    <published>2024-12-23T13:33:22.000Z</published>
    <updated>2024-12-24T14:20:11.887Z</updated>
    
    <content type="html"><![CDATA[<p>本文将介绍2010年由VMware公司提出的商业级的容错虚拟机系统，该系统基于VMware vSphere 4.0设计。该系统通过在另一台服务器上复制主虚拟机的执行来提供容错支持，同时可以在故障发生后自动恢复冗余。</p><p>论文参考：<a href="https://pdos.csail.mit.edu/6.824/papers/vm-ft.pdf">《The Design of a Practical System for Fault-Tolerant Virtual Machines》</a></p><h1 id="虚拟机容错技术"><a href="#虚拟机容错技术" class="headerlink" title="虚拟机容错技术"></a>虚拟机容错技术</h1><p>&emsp;&emsp;在现代服务器架构中，容错技术对于保证服务的持续性和可靠性至关重要。其中，主备模式作为一种经典的容错解决方案，一直受到广泛关注。这种模式的核心在于维持一个随时可以接管的备用服务器，确保在主服务器发生故障时能够无缝切换。</p><p>&emsp;&emsp;传统的容错实现方式主要依赖于状态复制，即直接复制主服务器上的所有状态变化，包括CPU状态、内存内容和I&#x2F;O设备状态等。这种方法虽然直观，但需要消耗大量网络带宽，在实际应用中往往面临效率瓶颈。</p><p>&emsp;&emsp;相比之下，状态机方法提供了一种更为高效的解决方案。这种方法将服务器视为确定性的状态机，通过确保主备服务器从相同的初始状态启动，并按相同顺序接收输入请求来维持同步。这种方法大大减少了需要传输的数据量，提高了系统效率。</p><p>&emsp;&emsp;VMware vSphere 4.0平台在这一领域取得了重要突破。通过虚拟机技术，它成功实现了高效的容错系统。该系统基于确定性重放技术，不仅完整支持x86架构，还能在故障发生后自动在集群中启动新的备份虚拟机。</p><p>&emsp;&emsp;虚拟机平台为实现状态机方法提供了理想环境，因为虚拟机本身就是一个定义明确的状态机，而Hypervisor可以完全控制虚拟机的执行过程。这种实现方式不仅可以在普通商用硬件上直接部署，而且由于带宽需求较低，主备服务器可以部署在物理距离较远的位置，进一步提高了系统的可靠性。</p><p>&emsp;&emsp;这种创新的容错技术为企业级应用提供了强有力的保障，不仅确保了服务的连续性，还实现了故障后的自动恢复，代表了服务器容错技术的重要发展方向。</p><h1 id="FT（Fault-Tolerant）设计"><a href="#FT（Fault-Tolerant）设计" class="headerlink" title="FT（Fault-Tolerant）设计"></a>FT（Fault-Tolerant）设计</h1><p>VMware FT的基本配置如下图：<br><img src="/img/blog/VMwareFT/vmft_1.jpg" alt="VMware基本配置图"><br>&emsp;&emsp;在VMware的容错系统中，主备虚拟机采用了一种优雅的同步机制。主虚拟机在一台物理服务器上运行，而备份虚拟机则在另一台物理服务器上运行，两者保持虚拟锁同步，只是备份虚拟机会有轻微的时间延迟。系统的存储架构采用共享存储方案，主备虚拟机都可以访问存储在光纤通道或iSCSI磁盘阵列上的虚拟磁盘。在网络通信方面，只有主虚拟机会在网络上公开自己的存在，因此所有的网络输入、键盘输入和鼠标操作都只会直接发送给主虚拟机。</p><p>&emsp;&emsp;为了保持同步，系统设计了一个称为日志通道的网络连接(channel)。主虚拟机接收到的所有输入都会通过这个通道转发给备份虚拟机。系统还会传输必要的额外信息，确保备份虚拟机能以完全相同的方式执行非确定性操作。虽然备份虚拟机会执行相同的操作，但其输出会被hypervisor拦截，只有主虚拟机的输出才会返回给客户端。</p><p>&emsp;&emsp;为了确保系统的可靠性，主备虚拟机之间遵循特定的协议，包括备份虚拟机的显式确认机制，这样可以保证在主虚拟机发生故障时不会丢失数据。系统通过心跳检测和日志通道流量监控来及时发现虚拟机故障，并且即使在发生脑裂情况时，也能确保只有一个虚拟机接管执行。</p><h2 id="确定性重放的实现"><a href="#确定性重放的实现" class="headerlink" title="确定性重放的实现"></a>确定性重放的实现</h2><p>&emsp;&emsp;在VMware的容错系统中，虚拟机的执行可以被视为确定性状态机的复制。为了确保备份虚拟机的执行与主虚拟机完全一致，必须在相同的初始状态下启动两台虚拟机，并提供相同顺序的输入。然而，虚拟机的输入来源广泛，包括网络数据包、磁盘读取以及键盘和鼠标输入。此外，非确定性事件（如虚拟中断）和操作（如读取处理器时钟周期计数器）也会影响虚拟机的状态，这给复制执行带来了挑战。具体而言，复制虚拟机执行面临三个主要挑战：首先，需要准确捕获所有输入和非确定性因素，以确保备份虚拟机能够进行确定性执行；其次，需要正确地将这些输入和非确定性因素应用于备份虚拟机；最后，所有这些操作必须在不影响性能的情况下完成。此外，许多复杂的x86微处理器操作会产生未定义的非确定性副作用，这进一步增加了实现难度。</p><p>&emsp;&emsp;VMware的确定性重放技术正是为了解决这些问题而设计。它通过记录虚拟机的输入及其相关的所有非确定性因素，将信息以日志条目的形式写入日志文件，从而在后续可以精确重放虚拟机执行。在重放过程中，系统会在相应的指令流中准确地交付事件，例如定时器或I&#x2F;O完成中断等非确定性事件。VMware确定性重放实现了一种高效的事件记录和交付机制，采用了与AMD和Intel合作开发的硬件性能计数器等多种技术。与其他方法不同，VMware不需要将虚拟机执行划分为时间片（epoch），而是能够在每次中断发生时立即记录并在重放时高效地交付。通过这种方式，VMware确保了主备虚拟机之间的一致性，同时保持了良好的性能。</p><h2 id="FT协议"><a href="#FT协议" class="headerlink" title="FT协议"></a>FT协议</h2><p>&emsp;&emsp;在VMware的容错系统中，确定性重放技术用于生成必要的日志条目，以记录主虚拟机的执行。这些日志条目通过日志管道实时发送给备份虚拟机，而不是写入磁盘。备份虚拟机在接收到这些条目后，能够实时重放，从而确保其执行与主虚拟机完全一致。为了实现故障容错，必须在日志管道上增强日志条目的传输协议。</p><ul><li>输出要求（Output Requirement）：如果备份虚拟机在主虚拟机发生故障后接管执行，它必须以一种与主虚拟机之前发送给外部世界的所有输出完全一致的方式继续执行。</li></ul><p>&emsp;&emsp;虽然在主虚拟机故障，备份虚拟机接管后，备份虚拟机的执行可能会与主虚拟机有所不同，但只要满足输出要求，就不会丢失任何可见状态或数据，客户也不会感受到服务中断或不一致。为确保输出要求，系统会延迟任何外部输出（如网络数据包），直到备份虚拟机接收到所有必要的信息，以便能够重放到该输出操作的时刻。这意味着备份虚拟机必须先接收到所有在输出操作之前生成的日志条目。如果在主虚拟机执行输出操作后立即发生故障，备份虚拟机需要知道必须继续重放，直到达到输出操作的时刻，然后再“上线”成为新的主虚拟机。为此，系统引入了一个特定规则：</p><ul><li>输出规则（Output Rule）主虚拟机不能向外界发送输出，直到备份虚拟机收到并确认与该输出操作相关的日志条目。</li></ul><p>&emsp;&emsp;这一规则确保备份虚拟机能够准确重现主虚拟机在输出时的状态，从而保证在发生故障时的一致性。需要注意的是，这一规则并不要求停止主虚拟机的执行，只需延迟发送输出即可。由于操作系统通常采用非阻塞方式进行网络和磁盘输出，因此主虚拟机可以继续执行，不会因为输出延迟而受到影响。此外，在发生接管的情况下，无法保证所有输出都被精确地产生一次，但网络基础设施（如TCP）能够处理丢失和重复的数据包，从而减轻这一问题带来的影响。</p><p>下图是一个FT协议要求的流程展示：<br><img src="/img/blog/VMwareFT/vmft_2.jpg" alt="FT协议要求的流程"><br>图中由两条时间线组成，分别为主服务器和备份服务器，由主服务器到备份服务器的箭头表示一条日志条目被传输，由备份服务器到主服务器的箭头表示备份服务器对主服务器的回应。这里可以看到，在备份服务器接管后它可以从输出点继续主服务器的任务。</p><h2 id="故障检测与响应"><a href="#故障检测与响应" class="headerlink" title="故障检测与响应"></a>故障检测与响应</h2><p>&emsp;&emsp;在VMware的容错系统中，主虚拟机和备份虚拟机必须快速响应彼此可能发生的故障。如果备份虚拟机出现故障，主虚拟机会“上线”，即停止记录模式并正常执行。如果主虚拟机发生故障，备份虚拟机也需“上线”，但这一过程更为复杂。由于备份虚拟机的执行存在延迟，它可能会有一些已接收并确认但尚未消耗的日志条目。备份虚拟机需要继续重放这些日志条目，直到消耗完最后一条日志条目，然后才会转为正常执行模式，成为新的主虚拟机。在这个过程中，新的主虚拟机会开始向外界输出数据。为了确保网络正常工作，VMware FT会自动在网络上广播新主虚拟机的MAC地址。此外，新主虚拟机可能还需要重新发出一些磁盘I&#x2F;O请求。</p><p>&emsp;&emsp;为了检测主备虚拟机的故障，VMware FT使用UDP心跳机制监控运行容错虚拟机的服务器，并监控从主虚拟机到备份虚拟机的日志流量及其确认信息。正常情况下，日志流量应该是规律且持续的，因此如果日志条目或确认信息的流动停止超过特定超时时间（通常为几秒钟），则可能表明发生了故障。然而，这种故障检测方法可能会导致“脑裂”问题：如果备份服务器没有接收到来自主服务器的心跳信号，这可能意味着主服务器已故障，也可能只是网络连接丢失。如果备份虚拟机在主虚拟机仍在运行时错误地上线，可能会导致数据损坏。因此，必须确保只有一个虚拟机在检测到故障时上线。为避免脑裂问题，系统利用存储在共享存储上的虚拟磁盘。当任一虚拟机想要上线时，它会在共享存储上执行原子设置操作。如果操作成功，该虚拟机被允许上线；如果失败，则表明另一台虚拟机已经上线，此时当前虚拟机会自我终止。如果无法访问共享存储，则该虚拟机会等待直到可以访问。值得注意的是，如果由于存储网络故障导致无法访问共享存储，那么该虚拟机也无法进行有效工作。</p><p>&emsp;&emsp;最后，一旦发生故障并且某个虚拟机已上线，VMware FT会自动在另一台主机上启动新的备份虚拟机，以恢复冗余。这一过程对于实现有效的容错至关重要，并需要精心设计。</p><h1 id="FT的其他组件"><a href="#FT的其他组件" class="headerlink" title="FT的其他组件"></a>FT的其他组件</h1><p>&emsp;&emsp;为了创建一个可用的、健壮的和自动化的系统，还必须设计和实现许多其他的组件。</p><h2 id="启动和重启容错虚拟机"><a href="#启动和重启容错虚拟机" class="headerlink" title="启动和重启容错虚拟机"></a>启动和重启容错虚拟机</h2><p>&emsp;&emsp;在VMware的容错系统中，设计一个机制以在与主虚拟机相同的状态下启动备份虚拟机是至关重要的。这一机制同样适用于在发生故障后重启备份虚拟机。该机制需要能够处理处于任意状态的正在运行的主虚拟机，并且应尽量减少对主虚拟机执行的干扰，以免影响当前客户。为此，VMware FT采用了现有的VMotion功能。VMware VMotion允许在几乎没有中断的情况下将运行中的虚拟机从一台服务器迁移到另一台服务器，通常暂停时间少于一秒。VMware创建了一种修改版的VMotion，能够在远程服务器上创建主虚拟机的精确运行副本，而不销毁本地服务器上的虚拟机。这种FT VMotion会设置日志通道，使源虚拟机进入记录模式作为主虚拟机，而目标虚拟机则进入重放模式作为新的备份虚拟机。</p><p>&emsp;&emsp;启动备份虚拟机的另一个方面是选择运行它的服务器。容错虚拟机在访问共享存储的服务器集群中运行，因此所有虚拟机通常可以在集群中的任何服务器上运行。这种灵活性使得VMware vSphere能够在一个或多个服务器发生故障时恢复容错冗余。当发生故障并且主虚拟机需要新的备份虚拟机以重新建立冗余时，主虚拟机会通知集群服务。集群服务根据资源使用情况和其他约束条件确定最佳服务器来运行备份虚拟机，并调用FT VMotion来创建新的备份虚拟机。因此，VMware FT通常能够在几分钟内重新建立虚拟机冗余，而不会对容错虚拟机的执行造成明显干扰。</p><h2 id="管理日志通道"><a href="#管理日志通道" class="headerlink" title="管理日志通道"></a>管理日志通道</h2><p>日志通道和buffer关系如下图所示：<br><img src="/img/blog/VMwareFT/vmft_3.jpg" alt="日志通道和buffer"><br>&emsp;&emsp;在VMware的容错系统中，管理进程会为主虚拟机和备份虚拟机维护一个大型日志缓冲区。主虚拟机生成的日志条目会尽快刷新到日志通道，而备份虚拟机会及时读取这些条目并发送确认信息。这些确认信息帮助VMware FT确定何时可以发送因输出规则而延迟的输出。如果备份虚拟机遇到空的日志缓冲区，它会暂停执行，直到有新条目可用；这不会影响客户，因为在主虚拟机正常时，它不同外界交互。相反，如果主虚拟机的日志缓冲区满了，它必须暂停执行，可能会影响客户（无法处理请求）。因此，需设计机制以避免主日志缓冲区填满。同时，执行延迟过大可能导致问题。如果主虚拟机故障，备份虚拟机需要重放所有已确认的日志条目，因此希望保持执行延迟时间较小（不超过一秒）。为此，系统通过监测主备虚拟机之间的实时执行延迟来调整主虚拟机的CPU分配。如果备份虚拟机滞后超过一秒，主虚拟机会被减速（减少它的CPU分配数量）；反之则增加其CPU限制。这种减速通常很少发生，主要在系统压力较大时才会出现。</p><h2 id="FT虚拟机的操作"><a href="#FT虚拟机的操作" class="headerlink" title="FT虚拟机的操作"></a>FT虚拟机的操作</h2><p>&emsp;&emsp;在VMware的容错系统中，处理主虚拟机的各种控制操作是一个实际问题。例如，当主虚拟机被显式关闭时，备份虚拟机也应停止，避免尝试上线。此外，主虚拟机上的资源管理变更（如增加CPU共享）也应应用于备份虚拟机。为此，主虚拟机会通过日志通道向备份发送特殊控制条目，以执行相应操作。</p><p>&emsp;&emsp;一般来说，大多数操作应仅在主虚拟机上发起，而VMware FT会将必要的控制条目发送到备份虚拟机。唯一可以独立进行的操作是VMotion，即主备虚拟机可以分别迁移到其他主机，但VMware FT确保两者不会迁移到同一服务器，以保持容错能力。主虚拟机的VMotion比普通VMotion复杂，因为备份虚拟机必须在适当时刻与新的主虚拟机重新连接。备份虚拟机的VMotion也面临类似的问题，但更为复杂。在普通VMotion中，所有未完成的磁盘I&#x2F;O必须在最终切换时完成。对于主虚拟机，这一过程相对简单；而对于备份虚拟机，由于其需重放主虚拟机的执行，因此难以在特定时刻完成所有I&#x2F;O。为了解决这一问题，当备份虚拟机达到VMotion的最终切换点时，它会通过日志通道请求主虚拟机暂时暂停所有I&#x2F;O操作。这样，在重放主虚拟机的暂停操作时，备份虚拟机的I&#x2F;O也能自然地在同一执行点上被暂停。</p><h2 id="磁盘IO的实现问题"><a href="#磁盘IO的实现问题" class="headerlink" title="磁盘IO的实现问题"></a>磁盘IO的实现问题</h2><p>&emsp;&emsp;在VMware的容错系统中，磁盘I&#x2F;O的实现涉及多个细微问题。首先，由于磁盘操作是非阻塞的，多个同时访问同一磁盘位置的操作可能导致非确定性。此外，VM直接使用DMA进行虚拟机内存与磁盘之间的数据传输，这也可能引发非确定性。为了解决这一问题，VM会检测到任何I&#x2F;O竞争（虽然这种情况较少），并强制这些竞争的磁盘操作在主备虚拟机上顺序执行。</p><p>&emsp;&emsp;其次，磁盘操作可能与虚拟机内应用程序或操作系统的内存访问发生竞争。例如，当应用程序正在读取某个内存块时，如果同时进行对该块的磁盘读取，可能会导致非确定性结果。虽然这种情况不常见，但VM必须检测并处理。解决方案之一是暂时对目标内存页设置保护，以防止在磁盘操作进行时发生访问。由于更改内存管理单元（MMU）保护是一项昂贵的操作，VM选择使用“跳跃缓冲区”（bounce buffer）。跳跃缓冲区是一个临时缓冲区，其大小与正在访问的内存相同。磁盘读取操作会先将数据读入跳跃缓冲区，然后在I&#x2F;O完成时将数据复制到客户内存中；而写入操作则先将数据复制到跳跃缓冲区，再从该缓冲区写入磁盘。</p><p>&emsp;&emsp;第三，当主虚拟机发生故障并且备份虚拟机接管时，未完成的磁盘I&#x2F;O会引发问题。新晋升的主虚拟机无法确认这些I&#x2F;O是否已成功发出或完成。此外，由于备份虚拟机未发出这些I&#x2F;O，因此在继续运行时不会收到明确的I&#x2F;O完成信号，这可能导致客户操作系统启动中止或重置程序。VM可以发送错误完成信号来指示某个I&#x2F;O失败，但这可能会导致客户操作系统对本地磁盘错误反应不佳。因此，在备份虚拟机上线过程中，VM会重新发出待处理的I&#x2F;O请求。由于VM已经消除了所有竞争，并且所有I&#x2F;O都明确指定了访问的内存和磁盘块，这些磁盘操作即使已成功完成也可以重新发出（即它们是幂等的）。</p><h2 id="网络IO的实现问题"><a href="#网络IO的实现问题" class="headerlink" title="网络IO的实现问题"></a>网络IO的实现问题</h2><p>&emsp;&emsp;在VMware vSphere中，网络性能优化主要依赖于管理进程异步更新虚拟机网络设备的状态。然而，这种异步更新会引入非确定性，可能导致备份虚拟机的执行与主虚拟机不一致。因此，在容错模式下，禁用了异步网络优化，所有网络数据包的处理都需要通过管理进程进行。</p><p>&emsp;&emsp;在VMware的容错模式下，为了提高网络性能，采取了两项优化措施。首先，通过集群优化减少虚拟机的陷阱和中断。当虚拟机以足够的速度传输数据时，管理进程可以将多个数据包合并为一次传输操作，从而减少陷阱的数量。其次，为了降低数据传输的延迟，管理进程确保在发送和接收日志条目及确认信息时不会发生线程上下文切换。这是通过在TCP栈中注册特定函数来实现的，使得可以快速处理日志消息和确认信息。这些优化措施旨在确保在容错模式下仍能保持良好的网络性能。此外，当主虚拟机排队传输数据包时，系统会立即刷新相关的输出日志条目，以减少延迟。这些措施旨在确保在容错模式下仍能保持良好的网络性能</p><h1 id="一些替代方案"><a href="#一些替代方案" class="headerlink" title="一些替代方案"></a>一些替代方案</h1><h2 id="共享磁盘与非共享磁盘"><a href="#共享磁盘与非共享磁盘" class="headerlink" title="共享磁盘与非共享磁盘"></a>共享磁盘与非共享磁盘</h2><p>&emsp;&emsp;在默认设计中，主虚拟机和备份虚拟机共享相同的虚拟磁盘。这种设计确保在故障切换发生时，磁盘内容是正确且可用的。主虚拟机负责对共享磁盘进行实际写入，并且写入操作需遵循输出规则（Output Rule）的延迟要求。另一种设计是让主虚拟机和备份虚拟机拥有各自独立的虚拟磁盘。在这种情况下，备份虚拟机会对其虚拟磁盘进行所有写入操作，从而保持与主虚拟机磁盘内容的一致性。这种非共享设计在共享存储不可用或成本过高时非常有用，尤其是在主备虚拟机距离较远的情况下。</p><p>&emsp;&emsp;然而，非共享设计的一个缺点是，在启用容错时，两个虚拟磁盘必须以某种方式显式同步。此外，在发生故障后，磁盘可能会失去同步，因此在备份虚拟机重启后需要重新同步。非共享磁盘配置中可能没有可用于解决脑裂问题的共享存储，此时系统可以使用其他外部仲裁者，例如一个双方均可通信的第三方服务器。如果服务器属于一个包含多个节点的集群，则可以基于集群成员资格使用多数算法来决定哪个虚拟机可以上线。</p><p>非共享磁盘的结构如下图所示：<br><img src="/img/blog/VMwareFT/vmft_4.jpg" alt="非共享磁盘的结构"></p><h2 id="在备份虚拟机上执行磁盘读"><a href="#在备份虚拟机上执行磁盘读" class="headerlink" title="在备份虚拟机上执行磁盘读"></a>在备份虚拟机上执行磁盘读</h2><p>&emsp;&emsp;在VMware FT的默认设计中，备份虚拟机不直接读取其虚拟磁盘，而是通过日志通道接收磁盘读取结果。虽然这种设计确保了数据一致性，但对于频繁进行磁盘读取的工作负载，日志通道的流量可能较大。另一种替代设计是让备份虚拟机执行磁盘读取，从而消除对磁盘读取数据的日志记录。这可以减少日志通道的流量，但也带来复杂性。备份虚拟机必须等待所有磁盘读取完成，如果主虚拟机的读取成功而备份失败，则备份需重试该操作；反之，若主虚拟机读取失败，则需通过日志通道发送目标内存内容。在共享磁盘配置下，如果主虚拟机对某个位置进行读取后又进行写入，则写入操作必须延迟，直到备份虚拟机完成第一次读取。这种依赖关系增加了实现复杂性。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>&emsp;&emsp;VMware Fault-Tolerance (VMFT) 是一种关键的技术，旨在确保虚拟机在发生故障时的高可用性和连续性。通过主备虚拟机的架构，VMFT 实现了实时数据同步和无缝故障切换，使得在主虚拟机出现问题时，备份虚拟机能够迅速接管其任务，确保服务的持续运行。该技术通过使用确定性重放、共享或非共享磁盘配置以及优化的网络和磁盘 I&#x2F;O 操作来减少延迟和带宽消耗，从而提高性能。尽管 VMFT 的实现面临诸多挑战，如处理非确定性操作和确保数据一致性，但其在企业级应用中的重要性不容忽视。随着技术的发展，VMFT 将继续为用户提供更可靠的解决方案，以应对日益复杂的 IT 环境和业务需求。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本文将介绍2010年由VMware公司提出的商业级的容错虚拟机系统，该系统基于VMware vSphere 4.0设计。该系统通过在另一台服务器上复制主虚拟机的执行来提供容错支持，同时可以在故障发生后自动恢复冗余。&lt;/p&gt;
&lt;p&gt;论文参考：&lt;a href=&quot;https://</summary>
      
    
    
    
    <category term="Distributed" scheme="https://peacill.online/categories/Distributed/"/>
    
    
    <category term="Distributed" scheme="https://peacill.online/tags/Distributed/"/>
    
    <category term="Fault-Tolerant" scheme="https://peacill.online/tags/Fault-Tolerant/"/>
    
  </entry>
  
  <entry>
    <title>GFS: The Google file system</title>
    <link href="https://peacill.online/post/22157.html"/>
    <id>https://peacill.online/post/22157.html</id>
    <published>2024-12-22T05:20:45.000Z</published>
    <updated>2024-12-23T07:23:06.024Z</updated>
    
    <content type="html"><![CDATA[<p>本文将详细介绍由Google在2003年提出的分布式文件系统GFS（Google File System）。GFS是一个分布式的可扩展文件系统，主要用于大规模的数据密集型应用。</p><p>论文参考：<a href="https://pdos.csail.mit.edu/6.824/papers/gfs.pdf">《The Google File System》</a></p><h1 id="GFS设计"><a href="#GFS设计" class="headerlink" title="GFS设计"></a>GFS设计</h1><p>&emsp;&emsp;GFS是一个用于支持分布式应用程序的文件系统，在分布式文件系统中，我们需要考虑以下问题：首先，组件的失败是不可避免的，比如磁盘损坏，网络不稳定及应用程序Bug等，所以一个分布式的文件系统必须具备持续监控、错误检测、错误容忍和自动恢复的能力；其次，文件系统中的文件通常非常巨大，动辄几百GB，当然也有大量的小文件，所以分布式的文件系统中的IO操作和数据块大小必须精心设计；最后，大多数对分布式文件系统中的写操作通常是追加写，而不会对文件系统中已经存在的数据进行覆盖，所以提高系统的追加写性能和其原子性是非常重要的。GFS就是大致基于这些设计假设来设计的分布式文件系统。</p><h2 id="GFS设计假设"><a href="#GFS设计假设" class="headerlink" title="GFS设计假设"></a>GFS设计假设</h2><ol><li>文件系统由一些廉价的商用组件组成，它们有一定的失败（损坏）概率，所以他们需要自我检测并在失败时迅速自我恢复。</li><li>文件系统中的文件通常为大文件（100MB或更大），小文件也被支持，但不会被优化</li><li>文件系统的读工作负载通常由两种读操作组成：大规模的流式读取和小规模的随机读取。小规模随机读取通常由偏移量来控制，同时大量的小规模读取在文件系统中被重排，以减少文件读取过程中回溯。</li><li>文件系统的写工作负载通常为追加，很少去修改已经写入的数据，文件一经写入很少会被修改。系统支持随机少量数据的写入但不会对其做优化。</li><li>文件系统在并发写文件下要有高效的语义实现，要确保原子性和最小的同步开销。因为该系统经常会被当作生产者消费者队列来使用，或用于多路归并。</li><li>高带宽比低延迟更重要。</li></ol><h2 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h2><p>GFS主要提供以下接口：create、delete、open、close、read、write、snapshot和record append。</p><h2 id="系统构建"><a href="#系统构建" class="headerlink" title="系统构建"></a>系统构建</h2><p>&emsp;&emsp;GFS主要由以下几部分构成：单个master（主节点），多个chunkserver（块服务器）和多个client（客户机）。在GFS中文件被分为合适大小的区块，每个区块有一个chunk handle（区块句柄）唯一标定，这个句柄在区块建立时由master分配。默认每个区块在系统中存在三个备份。master保管所有文件的metadata（元数据），其中包括文件的命名空间、访问权限和文件到区块的映射，master会周期的通过HeartBeat消息同chunkserver通信，发布自己的命令并收集每个chunkserver的状态。client和chunkserver都不提供缓存功能。</p><p>GFS系统构件如下图所示：</p><p><img src="/img/blog/GFS/GFS1.jpg" alt="GFS构建图"></p><h3 id="单个master"><a href="#单个master" class="headerlink" title="单个master"></a>单个master</h3><p>&emsp;&emsp;单个master可以简化系统的设计，并且确保master通过全局的知识可以精确的控制区块的部署，但是为了不让单个的master变为系统的瓶颈，client的读写操作不会和master产生任何联系，它只会询问master应该请求那个chunkserver，同时缓存这个信息（减少和master的交流次数），一个简单的读操作流程如下：</p><ol><li>使用固定的块大小，client将应用程序指定的文件名和字节偏移量翻译成文件内的块索引。</li><li>client向主节点发送包含文件名和块索引的请求。</li><li>主节点回复对应的块句柄和每个备份所在的位置。同时客户端使用文件名和块索引作为键缓存该信息。</li><li>client访问最近的备份所在的chunkserver，通过块句柄和块的字节范围</li></ol><p>再次请求相同的文件内容时，client只需要从缓存中读出信息即可，无需再次请求master，除非缓存消失或者chunkserver损坏。</p><h3 id="区块大小"><a href="#区块大小" class="headerlink" title="区块大小"></a>区块大小</h3><p>&emsp;&emsp;GFS采用64MB作为块大小，远大于传统文件系统。每个块副本以Linux文件形式存储，使用延迟空间分配策略来避免空间浪费。这种大块设计具有三个主要优势：减少了客户端与主服务器的交互需求，因为同一数据块操作只需请求一次位置信息；客户端可与数据服务器保持持久TCP连接，降低网络开销；减少主服务器的元数据存储量，使其能完全保存在内存中。不过，大块设计也面临挑战：小文件通常只有一个数据块，多客户端同时访问时可能造成服务器热点问题。为此，系统采取了增加热点文件副本数量、错开应用启动时间等解决方案，并考虑实现客户端间直接数据传输。</p><h3 id="metadata（元数据）"><a href="#metadata（元数据）" class="headerlink" title="metadata（元数据）"></a>metadata（元数据）</h3><p>&emsp;&emsp;GFS（Google文件系统）中的元数据由主服务器存储，主要包括文件和块的命名空间、文件与块的映射关系以及每个块副本的位置。所有元数据保存在主服务器的内存中，命名空间和文件到块的映射通过操作日志进行持久化，以确保在主服务器崩溃时不会出现不一致。主服务器在启动时向每个chunkserver请求块位置的信息，而不持久保存这些信息。</p><p>&emsp;&emsp;由于元数据存储在内存中，主服务器的操作速度非常快，并且可以定期扫描状态以实现块垃圾回收、重新复制和负载均衡等功能。虽然内存限制了系统的块数量，但实际使用中，这并不是一个严重的问题，因为每个64MB的块仅需64字节的元数据，大多数文件包含多个完整的块，只有最后一个块是不完整的。</p><p>&emsp;&emsp;操作日志是GFS的核心，记录了关键的元数据变化，并定义了并发操作的顺序。为了保证日志的可靠性，GFS在多个远程机器上复制操作日志，并在将更改对客户端可见之前，确保日志记录已持久化。主服务器通过重放操作日志来恢复文件系统状态，并在日志增大时创建检查点以加快恢复过程。检查点以紧凑的B树形式存储，可以直接映射到内存中，从而提高查找速度和可用性。检查点创建过程不会影响系统性能，确保了系统的高效性和可靠性。</p><h2 id="一致性模型"><a href="#一致性模型" class="headerlink" title="一致性模型"></a>一致性模型</h2><p>&emsp;&emsp;GFS（Google文件系统）采用了一种宽松的一致性模型，既支持高度分布式的应用，又保持了实现的简单高效。</p><h3 id="GFS的一致性保证"><a href="#GFS的一致性保证" class="headerlink" title="GFS的一致性保证"></a>GFS的一致性保证</h3><ol><li>文件命名空间的变更操作是原子的，由主服务器独家处理。文件区域在数据变更后的状态取决于变更类型、是否成功以及是否有并发变更。成功且无并发写入的变更会使区域变为已定义状态；并发的成功变更会导致区域处于未定义但一致的状态；失败的变更则使区域变得不一致。</li><li>数据变更包括写入和记录追加两种操作。GFS保证在一系列成功的变更后，变更的文件区域将处于已定义状态，并包含最后一次变更写入的数据。这是通过在所有副本上按相同顺序应用变更，并使用块版本号检测过时副本来实现的。</li><li>GFS通过定期与数据服务器进行握手来识别故障，并通过校验和检测数据损坏。一旦发现问题，系统会尽快从有效副本恢复数据。只有在GFS反应之前所有副本都丢失的极端情况下，数据才会不可逆转地丢失，但即便如此，应用程序也会收到明确的错误提示，而不是损坏的数据。</li></ol><h3 id="应用程序的隐含语义"><a href="#应用程序的隐含语义" class="headerlink" title="应用程序的隐含语义"></a>应用程序的隐含语义</h3><p>&emsp;&emsp;GFS的应用程序通过几种简单技术来适应其宽松的一致性模型：依赖追加而非覆写、使用检查点机制以及写入自验证和自识别的记录。在典型应用场景中，写入程序从头到尾生成文件，完成后通过原子重命名操作确定文件名，或定期设置检查点标记写入进度。读取程序只处理到最后一个检查点的文件内容，确保数据处于已定义状态。这种追加方式比随机写入更高效，也更能抵御应用程序故障。对于多写入者并发追加的场景，系统通过”至少追加一次”的语义来保护每个写入者的输出。写入的记录包含校验和等额外信息以验证有效性，读取程序可以通过校验和识别并丢弃多余的填充和记录片段，必要时还可以使用记录中的唯一标识符过滤重复内容。</p><h1 id="GFS系统构件间的交互"><a href="#GFS系统构件间的交互" class="headerlink" title="GFS系统构件间的交互"></a>GFS系统构件间的交互</h1><p>这个章节将具体介绍GFS中master、client和chunkserver如何交互以实现我们前面提到的数据修改，原子的记录追加和快照。</p><h2 id="数据修改"><a href="#数据修改" class="headerlink" title="数据修改"></a>数据修改</h2><p>&emsp;&emsp;在GFS中，数据修改（mutation）是指改变块内容或元数据的操作，如写入或追加。为了在副本之间保持一致的变更顺序，GFS使用租约（lease）机制。主服务器将块租约授予一个副本，称为主副本（primary），该副本为所有变更指定一个串行顺序，所有副本按照这个顺序应用变更。租约的初始超时时间为60秒，但只要块正在被变更，主副本可以请求并通常会获得无限期的延长。</p><p>数据修改流程图如下：<br><img src="/img/blog/GFS/GFS2.jpg" alt="GFS数据修改流程"></p><p>以下是写入过程的控制流程：</p><ol><li>客户端向master询问当前持有块租约的chunkserver及其他副本的位置。如果没有租约，主服务器将其授予一个副本。</li><li>主服务器回复主副本的身份和其他（次级）副本的位置。客户端缓存这些数据，以便未来的变更，只需在主副本不可达或不再持有租约时再次联系master。</li><li>客户端将数据推送到所有副本，可以按任意顺序进行。每个chunkserver器会在内部LRU缓冲区缓存数据，直到数据被使用或过期。</li><li>一旦所有副本确认接收到数据，客户端向主副本发送写请求，请求中标识了之前推送的数据。主副本为接收到的所有变更分配连续的序列号，以提供必要的序列化，并按序列号顺序将变更应用于其本地存储的数据。</li><li>主副本将写请求转发给所有次级副本。每个次级副本按照主副本分配的序列号顺序应用变更。</li><li>所有次级副本回复主副本，表示已完成操作。</li><li>主副本向客户端回复。如果任何副本遇到错误，将报告给客户端。如果在主副本成功但某些次级副本失败，则请求被视为失败，修改区域处于不一致状态。客户端代码会通过重试失败的变更（3～7步）来处理这些错误。</li></ol><p>&emsp;&emsp;如果应用程序的写入较大或跨越块边界，GFS客户端代码会将其拆分为多个写操作，这些操作遵循上述控制流程，但可能与其他客户端的并发操作交错。因此，共享文件区域可能包含来自不同客户端的片段，但由于各个操作在所有副本上成功完成且顺序相同，最终结果仍然保持一致但未定义状态。</p><h2 id="数据流传输"><a href="#数据流传输" class="headerlink" title="数据流传输"></a>数据流传输</h2><p>&emsp;&emsp;GFS将数据流与控制流分离，以实现网络的高效利用。控制流从客户端流向主副本，再到所有次级副本；而数据则通过精心选择的chunkserver链进行流水线式传输。系统采用线性链式传输而非树形等其他拓扑结构，确保每台机器的网络带宽得到充分利用。每台机器将数据转发给网络拓扑中最”近”的、尚未接收数据的机器，从而避免网络瓶颈和高延迟链路。系统通过IP地址可以准确估算机器间的”距离”（这得益于Google的网络拓扑结构）。为了最小化延迟，数据通过TCP连接进行流水线传输。块服务器一旦接收到数据就立即开始转发，这种方式在全双工链路的交换网络中特别有效。</p><h2 id="原子的记录追加"><a href="#原子的记录追加" class="headerlink" title="原子的记录追加"></a>原子的记录追加</h2><p>&emsp;&emsp;GFS提供了一种称为记录追加（record append）的原子追加操作。在传统写入中，客户端需要指定数据写入的偏移量，导致并发写入可能产生数据片段混合的问题。而在记录追加中，客户端只需指定要追加的数据，GFS会将其原子性地追加到文件中，偏移量由GFS自行选择，并将该偏移量返回给客户端。这种方式类似于Unix中以O_APPEND模式打开文件的写入，避免了多写入者并发时的竞争条件。</p><h2 id="快照"><a href="#快照" class="headerlink" title="快照"></a>快照</h2><p>&emsp;&emsp;GFS的快照（snapshot）操作能够几乎瞬间复制文件或目录树，同时最小化对正在进行的变更的干扰。用户可以利用快照快速创建大型数据集的分支副本，或在进行实验性更改前保存当前状态。快照实现采用写时复制技术。当master收到快照请求时，首先撤销待快照文件中所有块的未过期租约，确保后续写入需要与master交互（必须重新请求master租约的持有者）。master将操作记录到磁盘后，通过复制源文件或目录树的元数据来更新内存状态。新创建的快照文件指向与源文件相同的数据块。当快照操作后客户端首次要写入某个块时，master会注意到该块的引用计数大于1。此时，master会选择一个新的块标识符，并要求拥有当前副本的块服务器创建新块。通过在相同的块服务器上创建新块，确保数据可以在本地复制，避免网络传输，提高效率。之后的请求处理与普通块处理相同。</p><h1 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h1><p>&emsp;&emsp;master在GFS中负责执行所有命名空间操作，同时管理整个系统中的块副本。其核心职责包括决定块的放置位置、创建新的块和副本、协调系统范围的活动，以确保块的完整复制、在块服务器之间实现负载均衡，以及回收未使用的存储空间。</p><h2 id="基于读写锁的命名空间管理"><a href="#基于读写锁的命名空间管理" class="headerlink" title="基于读写锁的命名空间管理"></a>基于读写锁的命名空间管理</h2><p>&emsp;&emsp;GFS主服务器的操作可能耗时较长，为了避免延迟其他操作，系统采用锁机制来确保命名空间区域的正确序列化。与传统文件系统不同，GFS不维护目录数据结构，也不支持文件别名，而是将命名空间表示为一个将完整路径名映射到元数据的查找表。GFS的锁机制基于命名空间树中的节点，每个节点都有一个读写锁。操作执行时，会获取相关路径上的一系列锁。例如，对于路径&#x2F;d1&#x2F;d2&#x2F;…&#x2F;dn&#x2F;leaf的操作，会获取各级目录的读锁（&#x2F;d1, &#x2F;d1&#x2F;d2, … , &#x2F;d1&#x2F;d2…&#x2F;dn的读锁），以及最终路径（&#x2F;d1&#x2F;d2&#x2F;…&#x2F;dn&#x2F;leaf）的读锁或写锁。这种设计允许同一目录下的并发修改操作，比如多个文件可以同时在同一目录下创建。为了防止死锁，锁的获取遵循一致的顺序规则：首先按命名空间树的层级排序，同一层级内按字典序排序。考虑到命名空间可能包含大量节点，读写锁对象采用懒加载方式分配，不使用时即被删除。</p><h2 id="副本部署"><a href="#副本部署" class="headerlink" title="副本部署"></a>副本部署</h2><p>&emsp;&emsp;GFS集群在多个层面上实现高度分布式：数百个chunkserver分布在多个子网上，同时被来自相同或不同子网的数百个客户端访问。不同子网间的机器通信可能需要经过多个网络交换机，且子网的带宽可能小于其内部所有机器的总带宽。块副本的部署策略主要取决于两个目标：最大化数据的可靠性和可用性，以及最大化网络带宽利用率。系统不仅要将副本分布在不同机器上以防止磁盘或机器故障，更要将块副本分布在不同子网上。这样即使某个子网出现故障（如网络交换机或电路故障），部分副本仍能存活并保持可用。这种策略也使得数据访问可以利用多个子网的总带宽，尽管写入流量需要经过多个子网，但为了数据的可用性这是必须作出的权衡。</p><h2 id="区块（副本）的创建、重部署和再平衡"><a href="#区块（副本）的创建、重部署和再平衡" class="headerlink" title="区块（副本）的创建、重部署和再平衡"></a>区块（副本）的创建、重部署和再平衡</h2><h3 id="区块创建"><a href="#区块创建" class="headerlink" title="区块创建"></a>区块创建</h3><p>&emsp;&emsp;Master在创建新块时会综合考虑多个因素来决定副本的放置位置。首先，系统会选择磁盘利用率低于平均水平的chunkserver，这样可以随时间推移实现各服务器间的磁盘使用均衡。其次，会限制每个服务器上最近创建的块数量，因为新创建的块往往预示着即将到来的大量写入操作。最后，系统会确保将副本分布在不同子网上，以提高数据可靠性和可用性。</p><h3 id="区块重部署"><a href="#区块重部署" class="headerlink" title="区块重部署"></a>区块重部署</h3><p>&emsp;&emsp;当某个块的可用副本数量低于用户指定的目标值时，系统会触发重新复制机制。这种情况可能由多种原因导致，比如chunkserver不可用、副本损坏或磁盘故障等。系统会根据以下因素为需要复制的块分配优先级：</p><ol><li>与目标副本数的差距（失去两个副本比失去一个副本的优先级更高）</li><li>文件的活跃状态（活跃文件优先于已删除文件）</li><li>是否影响客户端操作（阻塞客户端进度的块会获得更高优先级）</li></ol><h3 id="区块再平衡"><a href="#区块再平衡" class="headerlink" title="区块再平衡"></a>区块再平衡</h3><p>&emsp;&emsp;Master会定期检查系统中副本的分布情况，并通过移动副本来优化磁盘空间使用和负载均衡。在处理新加入的chunkserver时，系统采用渐进式填充策略，避免突然分配大量数据而导致过重的写入负载。为了防止复制操作影响正常客户端访问，系统会对整个集群和单个chunkserver的同时复制操作数量进行限制，并通过限制带宽来控制复制速度。</p><p>这种多层次的副本管理机制确保了GFS能够在保持高可用性的同时，实现良好的负载均衡和资源利用率</p><h1 id="GFS的垃圾回收机制"><a href="#GFS的垃圾回收机制" class="headerlink" title="GFS的垃圾回收机制"></a>GFS的垃圾回收机制</h1><h2 id="回收机制"><a href="#回收机制" class="headerlink" title="回收机制"></a>回收机制</h2><p>&emsp;&emsp;当用户（client）删除一个文件时，GFS中的垃圾回收机制会被触发。当文件被删除后，系统不会立即回收其占用的物理存储空间，而是采用延迟处理的方式，这种懒惰回收的策略使得系统设计更加简单，同时也提高了系统的可靠性。这种方法虽然不会立即释放存储空间，但通过简化系统操作，降低了系统的复杂度，从而提高了整体的稳定性。</p><p>&emsp;&emsp;当应用程序删除文件时，master不会立即回收资源，而是将文件重命名为包含删除时间戳的隐藏文件。这些文件在三天内（可配置）仍然可以被读取和恢复。超过期限后，master会在例行扫描时删除这些隐藏文件的元数据，切断它们与数据块的联系（删除它的metadata）。</p><p>&emsp;&emsp;在master定期扫描数据块命名空间时，会识别出孤立的数据块（即无法从任何文件访问的块），并删除这些块的元数据。各个chunkserver在与master进行HeartBeat通信时，会报告它们持有的数据块信息，master则会告知哪些数据块在元数据中已不存在，chunkserver随后可以删除这些块的副本。</p><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>&emsp;&emsp;这种垃圾回收方式比直接删除有几个优势：首先，它在大规模分布式系统中更可靠；其次，它将存储回收与master的常规后台活动合并，成本分摊且不影响主要业务；最后，延迟删除可以防止意外删除（Rename文件就可以恢复它）。主要缺点是在存储空间紧张时可能会影响用户对存储空间的精细控制，对此系统提供了一些解决方案，比如允许用户为不同的命名空间设置不同的复制和回收策略。</p><h2 id="旧副本（无效副本）检测"><a href="#旧副本（无效副本）检测" class="headerlink" title="旧副本（无效副本）检测"></a>旧副本（无效副本）检测</h2><p>&emsp;&emsp;Master为每个数据块维护一个版本号，用于区分最新和过期的副本。当master授予数据块新的租约时，会增加版本号并通知所有最新的副本。master和这些chunkserver都会在持久存储中记录新的版本号，这个过程发生在通知客户端之前。</p><p>&emsp;&emsp;如果某个chunkserver在宕机期间错过了数据块的修改，其副本就会变得过期。当这个服务器重启并报告其数据块信息时，master会通过比对版本号发现过期的副本。如果master发现某个版本号比自己记录的更高，它会认为这是由于自己在授予租约时发生了故障，并采用较高的版本号作为最新版本。</p><p>master会在常规垃圾回收中移除过期副本。在此之前，当回应客户端请求数据块信息时，它会完全忽略过期副本的存在。作为额外的安全措施，master在告知客户端哪个chunkserver持有租约，或指示chunkserver从其他服务器克隆数据时，都会包含版本号信息。客户端或chunkserver在执行操作时会验证版本号，确保始终访问最新的数据。</p><h1 id="错误容忍与诊断"><a href="#错误容忍与诊断" class="headerlink" title="错误容忍与诊断"></a>错误容忍与诊断</h1><p>&emsp;&emsp;在分布式系统中，处理频繁的组件故障是最大的挑战之一。由于系统规模庞大且使用大量普通硬件设备，组件故障已经成为一种常态而非异常情况。系统既不能完全信任机器，也不能完全信任磁盘的可靠性。这些组件故障可能导致系统不可用，更严重的是可能造成数据损坏。因此，GFS必须建立相应的故障诊断工具和机制来应对这些不可避免的问题。</p><h2 id="高可用性"><a href="#高可用性" class="headerlink" title="高可用性"></a>高可用性</h2><p>&emsp;&emsp;高可用性主要由两个简单且高效的机制保证：快速恢复和复制（冗余）。</p><h3 id="快速恢复"><a href="#快速恢复" class="headerlink" title="快速恢复"></a>快速恢复</h3><p>&emsp;&emsp;master和chunkserver都被设计为能在几秒钟内恢复状态并重新启动，无论是何种原因导致的终止。系统对正常终止和异常终止的处理方式是一样的，服务器甚至可以通过直接终止进程的方式来进行例行关闭。当服务器重启时，客户端和其他服务器只会经历短暂的中断：它们会在当前请求超时后，重新连接到重启的服务器并重试之前的操作。</p><h3 id="块复制"><a href="#块复制" class="headerlink" title="块复制"></a>块复制</h3><p>&emsp;&emsp;每个数据块都会在不同机架的多个chunkserver上进行复制。用户可以为文件系统命名空间的不同部分指定不同的复制级别，默认是三个副本。当chunkserver离线或通过校验和验证检测到损坏的副本时，master会克隆现有副本以保持每个数据块的完整复制。</p><p>&emsp;&emsp;虽然复制机制运行良好，但系统也在探索其他形式的跨服务器冗余方案，如奇偶校验或纠删码，以满足不断增长的只读存储需求。由于系统的流量主要是追加写入和读取操作，而不是小型随机写入，因此在这种松耦合系统中实现这些更复杂的冗余方案虽然具有挑战性，但仍是可控的。</p><h3 id="Master复制"><a href="#Master复制" class="headerlink" title="Master复制"></a>Master复制</h3><p>&emsp;&emsp;为了保证可靠性，master的状态会在多台机器上进行复制，包括操作日志和检查点。只有当日志记录在本地磁盘和所有master副本上都完成刷新后，对状态的修改才被视为已提交。为了简单起见，一个master进程负责所有的修改操作和后台活动。如果master发生故障，它可以几乎立即重启；如果其机器或磁盘出现故障，GFS外部的监控基础设施会在其他地方启动新的master进程。</p><p>&emsp;&emsp;系统还设置了”影子”master，提供文件系统的只读访问服务。这些影子master与主master可能会有轻微的时间差，通常是几分之一秒。它们主要用于提高那些不经常修改的文件或对略微过期的结果可以容忍的应用程序的读取可用性。由于文件内容是从chunkserver读取的，应用程序不会看到过期的文件内容，可能过期的只是文件元数据，如目录内容或访问控制信息。影子master通过读取操作日志副本并按照与主master相同的顺序应用更改来保持信息更新。它们在启动时会轮询chunkserver以定位数据块副本，并通过定期的握手消息监控其状态。影子master只在副本位置更新方面依赖主master，这些更新是由主master创建和删除副本的决策产生的。</p><h2 id="数据完整性"><a href="#数据完整性" class="headerlink" title="数据完整性"></a>数据完整性</h2><p>&emsp;&emsp;GFS主要通过校验和来保障块及其副本的数据完整性。</p><p>&emsp;&emsp;每个chunkserver使用校验和技术来检测存储数据的损坏。由于GFS集群通常拥有数千个磁盘和数百台机器，定期会发生磁盘故障，导致读取和写入路径上的数据损坏或丢失。虽然可以通过其他副本恢复数据，但通过比较不同chunkserver之间的副本来检测损坏是不切实际的。此外，因GFS的修改语义（尤其是原子记录追加）可能导致不同的副本是合法的，因此每个chunkserver必须独立验证其副本的完整性，方法是维护校验和。</p><p>&emsp;&emsp;每个chunk被分为64 KB的块，每个块都有一个对应的32位校验和。校验和与其他元数据一样，保存在内存中并与日志一起持久存储。对于读取操作，chunkserver在返回数据之前会验证重叠读取范围内的数据块的校验和，从而避免将损坏的数据传播到其他机器。如果块与记录的校验和不匹配，chunkserver会向请求者返回错误并将不匹配情况报告给master。请求者会从其他副本读取，而master则会从另一个副本克隆该chunk。在有效的新副本就位后，master会指示报告不匹配的chunkserver删除其副本。</p><p>&emsp;&emsp;校验和对读取性能影响较小，因为大多数读取操作跨越多个块，只需读取相对较少的额外数据进行验证。此外，chunkserver上的校验和查找和比较不涉及任何I&#x2F;O操作，且校验和计算通常可以与I&#x2F;O操作重叠。对于追加写入操作，校验和计算经过优化，只需增量更新最后一个部分块的校验和，并为新填充的任何完整块计算新的校验和。如果最后一个部分块已损坏且未被及时检测到，新的校验和值在下次读取时仍会发现不匹配。</p><p>&emsp;&emsp;相反，对于覆盖写入操作，需要在写入之前读取并验证被覆盖范围的首尾块，然后执行写入并计算记录新的校验和。在未验证首尾块之前进行部分覆盖写入可能会隐藏未被覆盖区域的损坏。在空闲期间，chunkserver可以扫描并验证不活跃chunks的内容，以检测不常读取chunks中的损坏。一旦发现损坏，master可以创建新的未损坏副本并删除损坏副本，从而防止不活跃但已损坏的副本误导master认为有足够有效的副本存在。</p><h2 id="诊断工具"><a href="#诊断工具" class="headerlink" title="诊断工具"></a>诊断工具</h2><p>&emsp;&emsp;GFS系统通过详细的诊断日志记录显著提升了问题隔离、调试和性能分析的能力，同时只带来了极小的成本。没有日志，很难理解机器之间瞬时且不可重复的交互。GFS服务器生成的诊断日志记录了许多重要事件（如chunkserver的上下线）以及所有RPC请求和响应。这些诊断日志可以在不影响系统正确性的情况下自由删除，但应当尽量在空间允许的情况下保留这些日志。</p><p>&emsp;&emsp;RPC日志包括在网络上发送的确切请求和响应，除了正在读取或写入的文件数据。通过将请求与响应匹配并整理不同机器上的RPC记录，我们可以重建整个交互历史以诊断问题。这些日志也可作为负载测试和性能分析的追踪记录。由于这些日志是顺序和异步写入的，因此其对性能的影响很小，且远远被其带来的好处所抵消。最新事件也会保存在内存中，以便进行持续的在线监控。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>&emsp;&emsp;GFS展示了在商品硬件上支持大规模数据处理工作负载所需的关键特性。尽管某些设计决策是针对Google独特环境的，但许多原则也适用于类似规模和成本意识的数据处理任务。GFS通过重新审视传统文件系统的假设，以适应当前和预期的应用工作负载及技术环境，做出了根本性的设计改变。</p><p>&emsp;&emsp;GFS将组件故障视为常态，优化了主要以追加方式写入的大文件，并在读取时通常采用顺序方式。系统通过持续监控、复制关键数据以及快速自动恢复来提供容错能力，数据块复制使其能够容忍chunkserver的故障。此外，GFS开发了一种在线修复机制，能够定期且透明地修复损坏并尽快补偿丢失的副本。校验和技术则用于检测磁盘或IDE子系统级别的数据损坏，这在系统中存在大量磁盘的情况下变得尤为重要。</p><p>&emsp;&emsp;通过将文件系统控制与数据传输分离，GFS为多个并发读写者提供了高总吞吐量。较大的块大小和chunk租约的设计减少了master在常见操作中的参与，使得简单的集中式master不会成为瓶颈。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本文将详细介绍由Google在2003年提出的分布式文件系统GFS（Google File System）。GFS是一个分布式的可扩展文件系统，主要用于大规模的数据密集型应用。&lt;/p&gt;
&lt;p&gt;论文参考：&lt;a href=&quot;https://pdos.csail.mit.edu/</summary>
      
    
    
    
    <category term="Distributed" scheme="https://peacill.online/categories/Distributed/"/>
    
    
    <category term="Distributed" scheme="https://peacill.online/tags/Distributed/"/>
    
    <category term="File System" scheme="https://peacill.online/tags/File-System/"/>
    
  </entry>
  
  <entry>
    <title>Golang编程技巧——TDD</title>
    <link href="https://peacill.online/post/50511.html"/>
    <id>https://peacill.online/post/50511.html</id>
    <published>2024-12-21T08:14:32.000Z</published>
    <updated>2024-12-22T09:56:21.410Z</updated>
    
    <content type="html"><![CDATA[<p>本文将介绍一种应用于Go语言中的编程技巧TDD（Test Driven Development测试驱动开发），这一技巧主要得益于Go语言强大的testing包。</p><p>参考书目：《Go Design Pattern》</p><h1 id="Testing与TDD"><a href="#Testing与TDD" class="headerlink" title="Testing与TDD"></a>Testing与TDD</h1><p>&emsp;&emsp;当我们开始实现一段代码时，我们可能不会想到为这段代码加上测试，因为这段代码的体量还不算庞大。但随着代码量的增大，我们需要测试一些功能就会变得异常困难，这主要是因为代码量的提升和相互之间的调用导致我们无法快速的定位到出现问题的代码。所以在开始代码编写时就考虑功能测试是有必要的。</p><p>&emsp;&emsp;Golang有一个强大的测试包（testing），可以让您轻松地在TDD环境中工作。通过这个包，我们可以很方便的检查部分代码，而无需编写一个调用整个程序的main函数。</p><h1 id="testing包"><a href="#testing包" class="headerlink" title="testing包"></a>testing包</h1><p>&emsp;&emsp;测试对于每种语言来说都至关重要，go语言原生的提供了这个包，你无需通过第三方包或应用来测试你的代码。接下来我们讨论如何应用testing这个包。</p><p>&emsp;&emsp;首先我们需要一段需要测试的代码，如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">&quot;fmt&quot;</span></span><br><span class="line"><span class="string">&quot;os&quot;</span></span><br><span class="line"><span class="string">&quot;strconv&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">sum</span><span class="params">(a, b <span class="type">int</span>)</span></span> <span class="type">int</span> &#123;</span><br><span class="line"><span class="keyword">return</span> a + b</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">a, _ := strconv.Atoi(os.Args[<span class="number">1</span>])</span><br><span class="line">b, _ := strconv.Atoi(os.Args[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">result := sum(a, b)</span><br><span class="line">fmt.Printf(<span class="string">&quot;The sum of  %d and %d is %d\n&quot;</span>, a, b, result)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码非常简单通过命令行读入两个参数，并将他们相加，你可以在命令行中运行他们通过以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ go run sum.go 1 2</span><br></pre></td></tr></table></figure><p>接下来我们将创建一个测试文件来对这段代码进行测试，按照惯例，你的测试文件应该是在你正在测试的文件名的基础上加上_test后缀。所以，测试文件应该命名为sum_test.go。具体内容如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;testing&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TestSum</span><span class="params">(t *testing.T)</span></span> &#123;</span><br><span class="line">a := <span class="number">2</span></span><br><span class="line">b := <span class="number">3</span></span><br><span class="line">expected := <span class="number">5</span></span><br><span class="line"></span><br><span class="line">res := Sum(a, b)</span><br><span class="line"><span class="keyword">if</span> res != expected &#123;</span><br><span class="line">t.Errorf(<span class="string">&quot;Sum function error: %d + %d isn&#x27;t %d&quot;</span>,a, b, res)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>go语言中的测试函数通过以Test开头的方式来编写，同时传入一个指针参数t *testing.T，可以通过一下命令运行测试：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ go <span class="built_in">test</span> -v</span><br></pre></td></tr></table></figure><p>这里的参数v表示我们需要从test中接收详细的输出。也可以加入-cover参数来检查测试代码的覆盖率，他会返回测试代码执行到的行占代码总行数的比例。</p><h1 id="TDD"><a href="#TDD" class="headerlink" title="TDD"></a>TDD</h1><p>&emsp;&emsp;所谓TDD，就是我们在实现我们的函数之前先为它写个测试，我们用一个乘法的例子来展示TDD的思想。我们首先给出函数的声明，但不实现，代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">multiply</span><span class="params">(a, b <span class="type">int</span>)</span></span> <span class="type">int</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>紧接着我们实现测试函数，代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;testing&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TestMultiply</span><span class="params">(t *testing.T)</span></span> &#123;</span><br><span class="line">a := <span class="number">1</span></span><br><span class="line">b := <span class="number">2</span></span><br><span class="line">expected := <span class="number">2</span></span><br><span class="line"></span><br><span class="line">res := multiply(a, b)</span><br><span class="line"><span class="keyword">if</span> res != expected &#123;</span><br><span class="line">t.Errorf(<span class="string">&quot;Sum function error: %d * %d isn&#x27;t %d&quot;</span>, a, b, res)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此时运行go test一定会提示FAIL，因为1 * 2 !&#x3D; 0。目前我们有一个函数的声明和一个失败的测试，在此基础上，我们就可以开始真正乘法功能的实现了。代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">multiply</span><span class="params">(a, b <span class="type">int</span>)</span></span> <span class="type">int</span> &#123;</span><br><span class="line"><span class="keyword">return</span> a * b</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行go test之后你会看到成功的标志，虽然我们这里没有提供一个完整的main函数去运行multiply，但我们还是测试了我们的实现是否正确，这就是go语言中testing包的强大之处。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>&emsp;&emsp;当我第一次接触到这种技巧的时候也是非常不习惯，但当后期我的代码越来越复杂时，我发现这种编程技巧可以帮助你很好的定位到你代码中的错误，你可以在*_test.go中写不同的测试用于测试不同的函数，甚至是同一函数的不同功能，你只需要在go test的参数中加入-run&#x3D;*来进行测试函数的匹配，这里-run是进行正则匹配的，你无需为其提供完整的函数名（函数名不要包含Test）。</p><p>&emsp;&emsp;这篇文章到这里就结束了，可能有些唐突，希望你可以感受到TDD的魅力。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本文将介绍一种应用于Go语言中的编程技巧TDD（Test Driven Development测试驱动开发），这一技巧主要得益于Go语言强大的testing包。&lt;/p&gt;
&lt;p&gt;参考书目：《Go Design Pattern》&lt;/p&gt;
&lt;h1 id=&quot;Testing与TDD&quot;</summary>
      
    
    
    
    <category term="Golang" scheme="https://peacill.online/categories/Golang/"/>
    
    
    <category term="Golang" scheme="https://peacill.online/tags/Golang/"/>
    
  </entry>
  
  <entry>
    <title>Goroutine和Channel</title>
    <link href="https://peacill.online/post/52359.html"/>
    <id>https://peacill.online/post/52359.html</id>
    <published>2024-12-21T03:10:43.000Z</published>
    <updated>2024-12-22T09:56:39.907Z</updated>
    
    <content type="html"><![CDATA[<p>本文将简要介绍golang中的并发和线程间通信机制，主要围绕goroutine和channel展开。并通过两个demo说明二者的具体使用方法。通过channel我们可以实现lock free的数据结构，这在的第二个demo中会有所体现。</p><p>参考书目：《Go语言圣经》、《Go语言高级编程》</p><h1 id="Golang并发"><a href="#Golang并发" class="headerlink" title="Golang并发"></a>Golang并发</h1><p>&emsp;&emsp;如今，Web服务器每时每刻都会处理成千上万的请求，而Go语言通过其轻量级的并发单元——Goroutine可以实现非常强大的并发性能。Goroutine的创建成本极低、内存占用极少，同时，Goroutine运行在用户态下，所以Goroutine间的切换无需繁杂的上下文切换，这些特性都铸就了Golang适合高并发的特性。Goroutine通过Channel来进行相互之间的安全通信，这种通信方式体现了Golang的并发编程哲学：不要通过共享内存来通信，而应通过通信来共享内存。</p><p>&emsp;&emsp;Go语言的并发体系理论是CSP（Communicating Sequential Process，通讯顺序进程），他是一种现代化的并发编程模型，在这种模型下，值会在各个运行实例（goroutine）中传递。多线程共享内存则是当今很多语言采用的更为传统的并发模型。</p><h1 id="Goroutine"><a href="#Goroutine" class="headerlink" title="Goroutine"></a>Goroutine</h1><p>&emsp;&emsp;在go语言中，每一个并发执行的单元叫做goroutine，其实我们只要编写过go语言程序就接触过goroutine，当我写下一个main函数时，编译运行后，就会有一个main函数运行在一个goroutine上。所以goroutine就相当于其它语言的线程，但又不同于线程，这一点在后面我会具体讨论。</p><p>&emsp;&emsp;我们可以非常随意的启动一个goroutine，就像下面这样：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">f()</span><br><span class="line"><span class="keyword">go</span> f()</span><br></pre></td></tr></table></figure><p>这时就会有一个独立的goroutine去执行函数f，你可以在main这个goroutine中执行其它的操作。</p><p>接下来是一个简单的例子：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;fmt&quot;</span></span><br><span class="line"><span class="string">&quot;time&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">go</span> spinner(<span class="number">100</span> * time.Millisecond)</span><br><span class="line"><span class="keyword">const</span> n = <span class="number">45</span></span><br><span class="line">fibN := fib(n)</span><br><span class="line">fmt.Printf(<span class="string">&quot;\rFibonacci(%d) = %d\n&quot;</span>, n, fibN)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">fib</span><span class="params">(x <span class="type">int</span>)</span></span> <span class="type">int</span> &#123;</span><br><span class="line"><span class="keyword">if</span> x &lt; <span class="number">2</span> &#123;</span><br><span class="line"><span class="keyword">return</span> x</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> fib(x<span class="number">-1</span>) + fib(x<span class="number">-2</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">spinner</span><span class="params">(delay time.Duration)</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line"><span class="keyword">for</span> _, r := <span class="keyword">range</span> <span class="string">`-\|/`</span> &#123;</span><br><span class="line">fmt.Printf(<span class="string">&quot;\r%c&quot;</span>, r)</span><br><span class="line">time.Sleep(delay)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个Demo会在一小段动画后输出：</p><blockquote><p>Fibonacci(45) &#x3D; 1134903170</p></blockquote><p>&emsp;&emsp;这里我们在main这个goroutine内启动了另一个goroutine去执行spinner()，当main()输出最终结果并返回后，所有的过肉体呢都会被直接打断，程序退出。除了main()函数退出之外，没有其他的编程方法可以让一个goroutine打断另一个goroutine，除非通过channel，这个我们后面会提到。</p><h2 id="Groutine与系统线程"><a href="#Groutine与系统线程" class="headerlink" title="Groutine与系统线程"></a>Groutine与系统线程</h2><p>&emsp;&emsp;了解goroutine和系统线程的区别可以帮助我们更好的理解为什么go语言非常适合高并发。</p><h3 id="动态栈"><a href="#动态栈" class="headerlink" title="动态栈"></a>动态栈</h3><p>&emsp;&emsp;每个OS线程的栈大小都是固定的，一般为2MB，这个栈会被用来存储当前正在被调用或者挂起的函数的内部变量，2MB的大小对一个很小的goroutine来说存在着很大的资源浪费，或许它完全用不到那么大的空间。对一个go语言程序来说，我们可能创建成百上千个goroutine，如果每个goroutine都需要那么大的栈空间的话，那么我们就没有办法创建很多的goroutine，从而go也不在真正适合高并发。同时，2MB是个固定的大小，如果我们需要在一个goroutine中来运行一个复杂的深层次的递归的话，这个栈空间大小就会显得捉襟见肘。所以一个可以动态调整大小的栈被应用在go语言中。</p><p>&emsp;&emsp;每个goroutine在初始化后都会拥有一个很小的栈作为其生命周期的开始，一般为2KB。这个栈的用途同OS线程一样。但是，它的大小并不是固定的，而是可以动态的收缩，最大可以到1GB。动态大小的栈主要有两种方法来实现，一种方法是通过链栈，但是这种方法存在一定的性能问题，如链栈中的片段在内存中不一定是连续的，这会导致更多的缓存未命中；同时，我们需要为栈增加很多指针空间来将栈链接起来，这也是一种资源的浪费。go语言主要通过slice和内存管理来实现动态栈，类似于c++中的vector的内存分配方式，当栈的大小需要调整是，先检查栈后是否可以追加空间，如果可以则追加空间，如果不可，则重新进行更大空间的内存分配，并复制当前栈中的内容到新的空间。所以在这里有一个小小的陷阱，不要用其他语言的指针长时间的保存go语言的变量地址，因为随着栈空间的调整，这个地址是会发生变化的。</p><h3 id="Goroutine调度"><a href="#Goroutine调度" class="headerlink" title="Goroutine调度"></a>Goroutine调度</h3><p>&emsp;&emsp;OS线程会被操作系统内核调度，这个调度过程需要繁杂的上下文切换，也就是说操作系统首先需要从用户态转换为内核态，再保存当前线程的执行现场，同时将需要调度的线程的现场恢复，这几步操作非常慢，因为需要多次的内存访问。Go的运行时包含了其他的调度器，这个调度器采用m:n调度，也就是说，go的运行时会在n个OS线程上多工调度m个goroutine。这个调度器的调度过程与内核的调度时相似的，但是这个调度器只关注单独的go程序中的goroutine，它并不是一个硬件定时器，也就是说只有当这个goroutine阻塞时，调度器才会使其休眠，并调度执行另一个goroutine。同时，这种调度方法是不需要进行内核的上下文切换的，所以调度goroutine要比调度一个OS线程快的多。</p><p>&emsp;&emsp;我们可以通过一个变量GOMAXPROCS来决定有多少个OS线程同时执行go语言代码，它的默认值是CPU和核心数量。我们可以在运行代码时显示的指定这个值，如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ GOMAXPROCS = 1 go run example.go</span><br></pre></td></tr></table></figure><p>这样就只有一个操作系统线程在运行example.go。</p><h2 id="Groutine中的循环陷阱"><a href="#Groutine中的循环陷阱" class="headerlink" title="Groutine中的循环陷阱"></a>Groutine中的循环陷阱</h2><p>&emsp;&emsp;如果了解过go匿名函数（闭包）的话，你应该不会对下面这个例子陌生。匿名函数中的循环变量存在非常典型的快照问题。如果我们写出下面的代码：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> _, i := <span class="keyword">range</span> list &#123;</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="comment">// do something</span></span><br><span class="line">use(i)<span class="comment">// <span class="doctag">NOTE:</span> incorrect</span></span><br><span class="line">&#125;()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里的循环变量是被所有的匿名函数值所共享的，并且会在每次的循环迭代中更新。当一个goroutine开始执行use(i)时，i的值已经被循环更新，它看到的值是更新后的值，而不是goroutine被创建时的那个原本的值。我们可以通过显示的添加参数来解决这个问题，如：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> _, i := <span class="keyword">range</span> list &#123;</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(i <span class="type">int</span>)</span></span> &#123;</span><br><span class="line"><span class="comment">// do something</span></span><br><span class="line">use(i)<span class="comment">// correct</span></span><br><span class="line">&#125;(i)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这时每个goroutine都会接收到初始化它时传入的那个值了。</p><h1 id="Channel"><a href="#Channel" class="headerlink" title="Channel"></a>Channel</h1><p>&emsp;&emsp;Goroutine是go语言的并发体，channel就是他们之间的通讯机制，他可以通过一个goroutine向另一个goroutine发送信息，channel的创建和使用方式和goroutine一样简单，具体操作如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ch := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>)   <span class="comment">// A channel send and receive int</span></span><br><span class="line"><span class="keyword">var</span> x <span class="type">int</span></span><br><span class="line">ch &lt;- x<span class="comment">// send</span></span><br><span class="line">y := &lt;-ch<span class="comment">// receive</span></span><br><span class="line">&lt;-ch<span class="comment">// receive</span></span><br><span class="line"><span class="built_in">close</span>(ch)<span class="comment">// close a channel</span></span><br></pre></td></tr></table></figure><p>上述例子创建了一个无缓存的channel，当然我们也可以创建带缓存的channel：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd = <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>, <span class="number">10</span>)<span class="comment">// A channel with capacity 10</span></span><br></pre></td></tr></table></figure><p>同时，channel也可以是当方向的，如：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;-<span class="keyword">chan</span> <span class="type">int</span></span><br><span class="line"><span class="keyword">chan</span>&lt;- <span class="type">int</span></span><br></pre></td></tr></table></figure><p>前者是一个只能发送int类型的channel，而后者只能接收。</p><p>&emsp;&emsp;向无缓存的channel发送数据会导致发送者的goroutine阻塞，知道另一个goroutine执行接收操作。反之，如果接收操作发生在前，那么接收者的goroutine会阻塞直至另一个goroutine在该管道上执行发送。这个操作就像是两个goroutine之间做了一次同步操作，所以无缓存的channel也被称为同步channel。</p><p>&emsp;&emsp;带缓存的channel内部会持有一个元素队列，队列的最大容量可在make中指定，向缓存channel中发送操作就是向内部缓存队列的尾部插入元素，接收操作则是从队头删除。如果队列满，那么发送的goroutine阻塞，如果队列空，那么接收goroutine阻塞。</p><h1 id="Channel配合goroutine的一些用法"><a href="#Channel配合goroutine的一些用法" class="headerlink" title="Channel配合goroutine的一些用法"></a>Channel配合goroutine的一些用法</h1><p>&emsp;&emsp;有关goroutine和channel的概念就介绍这么多，还有很多没有办法在一篇文章中写完，可以参见参考书目，有更加详细的介绍。接下来会介绍一些channel配合goroutine的用法，也是一些代码技巧。</p><h2 id="缓存Channel——控制并发数量"><a href="#缓存Channel——控制并发数量" class="headerlink" title="缓存Channel——控制并发数量"></a>缓存Channel——控制并发数量</h2><p>&emsp;&emsp;当我们感受到goroutine的强大的并发特性之后，或许我们会写出最大并发化的代码，也就是无限的创建goroutine。但大部分时候我们需要控制好并发的程度，因为过大的并发会导致CPU资源被一个进程占尽，所以我们需要为其他进程预留CPU资源。</p><p>&emsp;&emsp;我们可以通过阻塞Channel来控制并发数量，具体做法如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> limit = <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> _, w := <span class="keyword">range</span> work &#123;</span><br><span class="line">        <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">            limit &lt;- <span class="keyword">struct</span>&#123;&#125;&#123;&#125;</span><br><span class="line">w()</span><br><span class="line">&lt;-limit</span><br><span class="line">&#125;()</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">select</span>&#123;&#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过这个名为limit的channel我们可以确保每时每刻最多只有3个goroutine处于运行状态。</p><h2 id="同步Channel——并发的安全退出"><a href="#同步Channel——并发的安全退出" class="headerlink" title="同步Channel——并发的安全退出"></a>同步Channel——并发的安全退出</h2><p>&emsp;&emsp;有时我们需要创建的goroutine集体退出，也就是说我们从一个goroutine中得到了想要的结果后就不需要其他的goroutine继续执行下去了。首先看看代码：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">worker</span><span class="params">(cancel <span class="keyword">chan</span> <span class="type">bool</span>)</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">fmt.Println(<span class="string">&quot;hello&quot;</span>)</span><br><span class="line"><span class="comment">// work</span></span><br><span class="line"><span class="keyword">case</span> &lt;-cancel:</span><br><span class="line"><span class="comment">// quit</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    cancel := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">bool</span>)</span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">        <span class="keyword">go</span> worker(cancel)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    time.Sleep(time.Second)</span><br><span class="line">    <span class="built_in">close</span>(cancel)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们通过关闭一个无缓存的管道来向所有的goroutine发送终止信号，所有从关闭的管道中接收的操作都会收到一个零值或者一个可选的失败的标志。但是这段代码还是不够稳健，有时我们需要等待所有的goroutine关闭后在退出主程序，以防goroutine泄漏，我们可以通过sync.WaitGroup来执行这个操作，集体做法不在这里展开。</p><h2 id="Channel——实现LockFree的数据结构"><a href="#Channel——实现LockFree的数据结构" class="headerlink" title="Channel——实现LockFree的数据结构"></a>Channel——实现LockFree的数据结构</h2><p>&emsp;&emsp;通过Channel我们可以实现一些lock free的并发访问操作，比如函数缓存。所谓函数缓存就是某些函数的调用通常需要非常长的时间（数据库访问，URL请求等），同时这个调用操作又需要多次执行，且每次访问都返回相同的值，这时我们就可以将函数的返回值缓存入一个map，每次调用前先访问map，看能否找到缓存，如果找不到，再去调用费时的函数，这个技巧可以优化一些程序的执行时间。</p><p>&emsp;&emsp;这里我们通过一个map来聊聊具体的做法，我们有一个需要并发访问的map，对这个map共有三个操作，insert、get和delete，具体代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> thread_safe_map</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">&quot;fmt&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> message <span class="keyword">struct</span> &#123;</span><br><span class="line">key   <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">value <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">ok    <span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line">err   <span class="keyword">chan</span> <span class="type">error</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> MyMap <span class="keyword">struct</span> &#123;</span><br><span class="line">mp    <span class="keyword">map</span>[<span class="keyword">interface</span>&#123;&#125;]<span class="keyword">interface</span>&#123;&#125; </span><br><span class="line"></span><br><span class="line">getch <span class="keyword">chan</span> message                </span><br><span class="line">delch <span class="keyword">chan</span> message                </span><br><span class="line">insch <span class="keyword">chan</span> message                </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewMyMap</span><span class="params">()</span></span> *MyMap &#123;</span><br><span class="line">m := &amp;MyMap&#123;</span><br><span class="line">mp:    <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">interface</span>&#123;&#125;]<span class="keyword">interface</span>&#123;&#125;), </span><br><span class="line">getch: <span class="built_in">make</span>(<span class="keyword">chan</span> message, <span class="number">100</span>),           </span><br><span class="line">delch: <span class="built_in">make</span>(<span class="keyword">chan</span> message, <span class="number">100</span>),           </span><br><span class="line">insch: <span class="built_in">make</span>(<span class="keyword">chan</span> message, <span class="number">100</span>),           </span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">go</span> m.schedule() </span><br><span class="line"><span class="keyword">return</span> m</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *MyMap)</span></span> Get(key <span class="keyword">interface</span>&#123;&#125;) (<span class="keyword">interface</span>&#123;&#125;, <span class="type">error</span>) &#123;</span><br><span class="line">msg := message&#123;</span><br><span class="line">key: key,</span><br><span class="line">ok:  <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;),</span><br><span class="line">err: <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">error</span>),</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">defer</span> <span class="built_in">close</span>(msg.ok)  </span><br><span class="line"><span class="keyword">defer</span> <span class="built_in">close</span>(msg.err)</span><br><span class="line"></span><br><span class="line">m.getch &lt;- msg</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> &lt;-msg.ok: </span><br><span class="line"><span class="keyword">return</span> msg.value, <span class="literal">nil</span> </span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> err := &lt;-msg.err:</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err </span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *MyMap)</span></span> Insert(key <span class="keyword">interface</span>&#123;&#125;, value <span class="keyword">interface</span>&#123;&#125;) <span class="type">error</span> &#123;</span><br><span class="line">msg := message&#123;</span><br><span class="line">key:   key,</span><br><span class="line">value: value,</span><br><span class="line">ok:    <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;),</span><br><span class="line">err:   <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">error</span>),</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">defer</span> <span class="built_in">close</span>(msg.ok)  </span><br><span class="line"><span class="keyword">defer</span> <span class="built_in">close</span>(msg.err)</span><br><span class="line">m.insch &lt;- msg</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> &lt;-msg.ok: </span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span> </span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> err := &lt;-msg.err:</span><br><span class="line"><span class="keyword">return</span> err </span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *MyMap)</span></span> Delete(key <span class="keyword">interface</span>&#123;&#125;) (<span class="keyword">interface</span>&#123;&#125;, <span class="type">error</span>) &#123;</span><br><span class="line">msg := message&#123;</span><br><span class="line">key: key,</span><br><span class="line">ok:  <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;),</span><br><span class="line">err: <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">error</span>),</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">defer</span> <span class="built_in">close</span>(msg.ok)  </span><br><span class="line"><span class="keyword">defer</span> <span class="built_in">close</span>(msg.err)</span><br><span class="line">m.delch &lt;- msg</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> &lt;-msg.ok: </span><br><span class="line"><span class="keyword">return</span> msg.value, <span class="literal">nil</span> </span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> err := &lt;-msg.err:</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err </span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *MyMap)</span></span> schedule() &#123;</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> msg := &lt;-m.getch:</span><br><span class="line">value, exists := m.mp[msg.key]</span><br><span class="line"><span class="keyword">if</span> !exists &#123;</span><br><span class="line">msg.err &lt;- fmt.Errorf(<span class="string">&quot;key %v not found&quot;</span>, msg.key)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">msg.value = value</span><br><span class="line">&#125;</span><br><span class="line">msg.ok &lt;- <span class="keyword">struct</span>&#123;&#125;&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> msg := &lt;-m.delch:</span><br><span class="line">value, exists := m.mp[msg.key]</span><br><span class="line"><span class="keyword">if</span> !exists &#123;</span><br><span class="line">msg.err &lt;- fmt.Errorf(<span class="string">&quot;key %v not found&quot;</span>, msg.key)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="built_in">delete</span>(m.mp, msg.key) </span><br><span class="line">msg.value = value     </span><br><span class="line">&#125;</span><br><span class="line">msg.ok &lt;- <span class="keyword">struct</span>&#123;&#125;&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> msg := &lt;-m.insch:</span><br><span class="line">m.mp[msg.key] = msg.value </span><br><span class="line">msg.ok &lt;- <span class="keyword">struct</span>&#123;&#125;&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个Demo中，只有一个goroutine（schedule）对map进行访问，所以也就不会存在数据竞争，通过这种方法我们可以实现一个lock free的数据结构。</p><blockquote><p><strong>NOTE：</strong>上面这个Demo并不能直接用于生产环境中，他还是存在很大的性能问题，如通过一个goroutine来执行对map的操作回导致操作的串行化，此时这个map就是整个系统的性能瓶颈。虽然这种操作方式可以省去加锁和释放锁过程中的性能开销，但如果需要频繁的对这个map进行访问，哪这个map就会是整个系统的瓶颈，所以这里只是提供了一种通过管道来实现lock free的思路而不是对map的高性能实现。</p></blockquote><blockquote><p>如果你要实现一个高性能的map这里可以提供一个思路：1. 通过细粒度的锁来控制这个map，如分段加锁。 2. delete操作不真正的删除数据，而是只修改它的标记位为已删除。 3. 当然也可以采用读写锁</p></blockquote><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>&emsp;&emsp;这篇博客到这里就结束了，其实我没有介绍太多关于goroutine和channel的基础知识，只是介绍了一些我觉得需要特别关注一下的地方和一些应用技巧，讲解并不全面，强大的goroutine和channel魔法是不可能通过一篇博客讲完的，需要我们不断的在应用中了解。所以最后，祝顺！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本文将简要介绍golang中的并发和线程间通信机制，主要围绕goroutine和channel展开。并通过两个demo说明二者的具体使用方法。通过channel我们可以实现lock free的数据结构，这在的第二个demo中会有所体现。&lt;/p&gt;
&lt;p&gt;参考书目：《Go语言圣</summary>
      
    
    
    
    <category term="Golang" scheme="https://peacill.online/categories/Golang/"/>
    
    
    <category term="Golang" scheme="https://peacill.online/tags/Golang/"/>
    
    <category term="Concurrency" scheme="https://peacill.online/tags/Concurrency/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce浅析</title>
    <link href="https://peacill.online/post/64376.html"/>
    <id>https://peacill.online/post/64376.html</id>
    <published>2024-12-17T11:20:57.000Z</published>
    <updated>2024-12-22T09:55:05.326Z</updated>
    
    <content type="html"><![CDATA[<!-- title: Hello World         # 标题tags: [Distributed]             # 标签categories:                     # 分类description: hello word~        # 描述top_img: /img/hello-1.png       # 顶部背景图cover: /img/hello-1.png         # 文章封面--- --><p>本文将详细介绍由Google提出的一种用于大规模数据集并行处理的编程模型和计算框架——MapReduce，该框架目前已经很少被用在生产环境中，但其背后的基本思想仍然在现代大数据处理技术中占有重要地位</p><p>论文参考：<a href="https://pdos.csail.mit.edu/6.824/papers/mapreduce.pdf">《MapReduce: Simplified Data Processing on Large Clusters》</a></p><h1 id="MapReduce框架"><a href="#MapReduce框架" class="headerlink" title="MapReduce框架"></a>MapReduce框架</h1><p>&emsp;&emsp;MapReduce是一个用于处理和生成大数据集的编程模型和相关实现。采用这个框架编写的程序会自动并行化，并在一个大规模的集群上运行。在大量数据集的处理过程中，用户只需指定相关的Map函数和Reduce函数，而无需关心框架背后的集群化处理过程。换句话说，用户可以像处理少量数据那样直接写处理函数（Map和Reduce），而无需关心背后集群到底将这些函数部署在集群中那个节点上或分配几个集群节点来运行这个函数。</p><h2 id="Map函数和Reduce函数"><a href="#Map函数和Reduce函数" class="headerlink" title="Map函数和Reduce函数"></a>Map函数和Reduce函数</h2><p>&emsp;&emsp;使用Map函数和Reduce函数的思想来源于：在绝大部分的数据处理过程中，我们都需要将输入的逻辑记录应用Map操作，生成一个键&#x2F;值对形式的中间数据，然后对所有的键&#x2F;值对应用Reduce操作来合并这些中间数据，以生成合适的最终结果。例如，我们需要统计大量文本中的单词数量（这个例子非常适合并行化处理），并输出最终的结果，那么代码结构就会像下面这样：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">map</span>(String key, String value):</span><br><span class="line">    <span class="keyword">for</span> each word w in value:</span><br><span class="line">        <span class="built_in">EmitIntermediate</span>(w, <span class="string">&quot;1&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="built_in">reduce</span>(String key, Iterator values):</span><br><span class="line">    <span class="type">int</span> result = <span class="number">0</span>; </span><br><span class="line">    <span class="keyword">for</span> each v in values:</span><br><span class="line">        result += <span class="built_in">ParseInt</span>(v);</span><br><span class="line">    <span class="built_in">Emit</span>(<span class="built_in">AsString</span>(result));</span><br></pre></td></tr></table></figure><p>其中，map函数中的key为输入文件的名称，values为文件内容。map函数将输入文件中的单词都处理为如(w, “1”)这样的键值对形式，map函数会将所有key相同的中间数据组合到一起形成一个list，并将其作为中间数据提交给Reduce函数，reduce函数接收每个形如（key，list()）的中间数据，并计算最终的结果，在这个例子中，reduce函数只需要计算与每个key关联的list列表的长度即可，因为map只是将形如(w, “1”)这样的键值对数据中值追加到了list中，每个值都是1。所以，MapReduce框架的数据处理过程如下：</p><blockquote><p>  map(k1, v1)             -&gt; list(k2, v2)<br>  reduce(k2, list(v2))    -&gt; list(v2)  </p></blockquote><h2 id="MapReduce框架工作流程"><a href="#MapReduce框架工作流程" class="headerlink" title="MapReduce框架工作流程"></a>MapReduce框架工作流程</h2><p>工作流程图如下：<br><img src="/img/blog/MapReduce/MapReduce1.jpg" alt="MapReduce工作流程"><br>工作流程：</p><ol><li>MapReduce库将用户输入的文件分割为M块，每块的大小通常为16MB～64MB（通过用户参数控制），然后在集群机器中启动一些程序副本。</li><li>在这些运行副本的机器中，有一个机器比较特殊，他被叫做主节点（master），其余节点被称为工作节点（worker）。主节点分配工作给工作节点，并进行工作负载的调度。</li><li>每个被分配了任务的工作节点读取输入，并从输入中解析出键值对，将其传入用户定义的Map函数，Map函数处理产生中间数据，这些中间数据会被缓存到内存中。</li><li>内存中的缓存数据会被定期的写入磁盘之中，并通过分区函数将其分为R个区块（这里的R是Reduce Worker的数量）。这些缓存的中间数据的存储位置会传回主节点，主节点将这些存储位置发送给执行Reduce函数的worker。</li><li>Reduce Worker在得到这些位置后，会使用RPC（远程过程调用）从Map Worker的本地磁盘中读取这些中间数据。Reduce Worker会按照中间键对这些数据进行排序，以便将键相同的数据组织在一起。排序过程是必要的，当数据量太大而无法直接放入内存时可以使用外部排序。</li><li>reduce worker遍历排序后的中间数据，并且将遇到的每个唯一中间键和其值传递给用户定义的Reduce函数，Reduce函数的输出被追加到该Reduce Worker的最终输出文件中。</li><li>所有的map任务和Reduce任务在集群中完成后，master会唤醒用户程序，对MapReduce的调用返回。</li></ol><p>最终对MapReduce调用的输出结果会被存储在R个文件中。通常这R个文件不会被合并，因为它们很可能会是下一个分布式过程的输入数据。</p><h2 id="master节点的数据结构"><a href="#master节点的数据结构" class="headerlink" title="master节点的数据结构"></a>master节点的数据结构</h2><p>&emsp;&emsp;在这个框架中，主节点需要维护大量的数据结构，对每一个分配给worker的map task和reduce task，master都需要维护他们的状态，以及他们所运行机器的ID。同时，主节点会维护每个中间数据的存储位置及其大小，并将其发送给每个Reduce Worker。</p><h2 id="分区函数（Partition-Function）"><a href="#分区函数（Partition-Function）" class="headerlink" title="分区函数（Partition Function）"></a>分区函数（Partition Function）</h2><p>&emsp;&emsp;用户可以通过参数R来指定Reduce任务或输出文件的数量，数据通过分区函数划分到这些任务中。默认的分区函数是一个hash函数，操作如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">hash</span>(key) mod R</span><br></pre></td></tr></table></figure><p>这样的划分通常是足够随机的，但是这样的划分方式会导致一个问题，可能会将我们需要聚集到一起的数据分散到不同的节点上。例如：有时我们希望输出的键是URL，所以我们希望同一hostname下的所有条目全部都被分配到同一文件中。为了支持这种特殊情况，MapReduce库的使用者可以提供一个特殊的分区函数。例如在上面这个例子中，分区函数可以是以下形式：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">hash</span>(<span class="built_in">hostname</span>(urlkey)) mod R</span><br></pre></td></tr></table></figure><p>使用这个分区函数，就可以使所有hostname下的条目最终被分配到同一文件中。</p><h1 id="错误容忍（Fault-Tolerance）"><a href="#错误容忍（Fault-Tolerance）" class="headerlink" title="错误容忍（Fault Tolerance）"></a>错误容忍（Fault Tolerance）</h1><p>&emsp;&emsp;在大集群中运行的过程都需要考虑出现错误的情况，这是不可避免的，比如集群中的部分集群出现损坏或磁盘损坏等。因此，像这些分布式的过程都需要优雅的容忍机器故障。</p><h2 id="worker出错（Worker-Failure）"><a href="#worker出错（Worker-Failure）" class="headerlink" title="worker出错（Worker Failure）"></a>worker出错（Worker Failure）</h2><p>&emsp;&emsp;master会周期的ping每个worker，如果master没有收到回应，则将该节点的状态置为失败，同时所有分配给他的任务都会被重置为初始状态并等待调度。<br>&emsp;&emsp;已经完成的map任务会被重新执行一遍，因为这个worker产生的中间数据被存储在他自己的磁盘中，这些数据是无法被master访问到的。已经完成的reduce任务无需重新执行，因为它的输出结果在集群全局的文件系统中。<br>&emsp;&emsp;当有worker在执行map任务的过程中被master标记为失败，那么所有执行reduce任务的worker都会被通知重新执行，确保数据读取过程不会出错。</p><h2 id="master出错（Master-Failure）"><a href="#master出错（Master-Failure）" class="headerlink" title="master出错（Master Failure）"></a>master出错（Master Failure）</h2><p>&emsp;&emsp;对master节点而言，它会周期的存储CheckPoint，来优雅的应对可能会出现的变故。</p><h2 id="原子操作来避免可能会发生的数据冲突"><a href="#原子操作来避免可能会发生的数据冲突" class="headerlink" title="原子操作来避免可能会发生的数据冲突"></a>原子操作来避免可能会发生的数据冲突</h2><p>&emsp;&emsp;map函数和reduce函数产生的输出都会被原子的写入到文件中，以防race condition的发生。 </p><h1 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h1><h2 id="数据本地化（Locality）"><a href="#数据本地化（Locality）" class="headerlink" title="数据本地化（Locality）"></a>数据本地化（Locality）</h2><p>&emsp;&emsp;网络带宽通常是构建大规模集群的性能瓶颈，MapReduce通过GFS文件系统来管理输入数据，这些输入数据被分成64MB的块，同时在集群中存在他们的三个副本。master节点负责管理输入文件的位置信息，它会首先尝试在该文件存在的机器上调度map task，如果不成功，则尝试在task的输入数据副本“附近”的机器上调度这个任务（例如，在与包含数据的机器位于同一网络交换机上的工作机器上）。在集群中的大规模MapReduce操作运行时，大多数输入数据都在本地读取，不消耗网络带宽。</p><h2 id="任务备份（Backup-Tasks）"><a href="#任务备份（Backup-Tasks）" class="headerlink" title="任务备份（Backup Tasks）"></a>任务备份（Backup Tasks）</h2><p>&emsp;&emsp;MapReduce方案的另一个性能瓶颈就是系统中的“拖延者”（straggler），也就是那些执行map函数或reduce函数非常慢的机器。例如，某些机器上的硬盘损坏使其硬盘读写速度大幅度下降，或者在这台机器上调度了过多的任务，导致它的执行时间变慢。这时master节点在整个MapReduce操作快要完成时，备份执行剩余的正在执行的任务。无论是备份的任务或者原本的任务，只要其中之一完成就将这个任务标记为完成。这种方法可以有效的减少系统中的straggler。</p><h2 id="结合函数（Combiner-Function）"><a href="#结合函数（Combiner-Function）" class="headerlink" title="结合函数（Combiner Function）"></a>结合函数（Combiner Function）</h2><p>&emsp;&emsp;在某些情况下，经过map函数操作后，可能会存在很多重复的中间数据，并且用户指定的Reduce函数需要将这些重复的中间数据组合在一起。例如，在我们上面提到的单词计数的程序，由于单词出现的频率往往服从Zipf分布，所以每个map函数产生的中间数据中可能会包含大量的形如（the， 1）这样的中间数据，而这些大量的数据都需要占用带宽通过网络发送给Reduce Worker，由Reduce Worker来计算单词的总数，这个过程会产生资源浪费。所以MapReduce框架允许用户指定一个Combiner 函数，在数据被发送到网络之前对数据进行初步的整合。<br>&emsp;&emsp;Combiner Function在每个Map Worker上运行，它通常拥有和Reduce函数相同的处理过程，只是最后的输出位置不同。Reduce函数将输出写入到最终的输出文件，这些输出文件别集群的文件系统管理；Combiner Function将输出写入到中间数据文件并最终发送给Reduce Worker。初步的整合可以显著的加快MapReduce的处理速度。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>&emsp;&emsp;MapReduce旨在通过并行和分布式的方式处理大规模数据集。它特别适合高效处理大量数据，是大数据处理的基石技术，尤其是在 Apache Hadoop 生态系统中。如今，他也被应用在机器学习等领域。MapReduce 提供了一种强大的模型，通过利用分布式计算资源来高效的处理大规模数据集。本文并未全面的探讨MapReduce框架，只是提供了一些基本的概念，如有兴趣，请参加其论文原文和具体代码实现。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;!-- title: Hello World         # 标题
tags: [Distributed]             # 标签
categories:                     # 分类
description: hello word~     </summary>
      
    
    
    
    <category term="Distributed" scheme="https://peacill.online/categories/Distributed/"/>
    
    
    <category term="Distributed" scheme="https://peacill.online/tags/Distributed/"/>
    
  </entry>
  
</feed>
